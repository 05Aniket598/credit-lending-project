{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7wHzfO69sqok",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wHzfO69sqok",
    "outputId": "1c99c088-43b0-4d9d-a798-a8a9cacbb33d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 10 16:14:47 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.99                 Driver Version: 555.99         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   50C    P8              7W /   75W |     181MiB /   6144MiB |      5%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3040      C   ...rograms\\Python\\Python313\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6338875f-4f71-4bee-b209-216b44eeb7b9",
   "metadata": {
    "id": "6338875f-4f71-4bee-b209-216b44eeb7b9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca43435d-0104-459e-874f-a5b968194a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 3.1.1\n",
      "✅ GPU training works!\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "print(\"Version:\", xgb.__version__)\n",
    "\n",
    "model = xgb.XGBClassifier(tree_method='hist',device='cuda')\n",
    "model.fit([[0,1],[1,0]], [0,1])\n",
    "print(\"✅ GPU training works!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "097807c4-891c-40d0-950a-7cfc82be6336",
   "metadata": {
    "id": "097807c4-891c-40d0-950a-7cfc82be6336",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_excel(r\"C:\\Users\\Aniket\\OneDrive\\Desktop\\Personal\\Projects\\Credit lending\\Project\\case_study1.xlsx\")\n",
    "data2 = pd.read_excel(r\"C:\\Users\\Aniket\\OneDrive\\Desktop\\Personal\\Projects\\Credit lending\\Project\\case_study2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a93a58cc-2424-4b42-8e07-fa21c51abe3a",
   "metadata": {
    "id": "a93a58cc-2424-4b42-8e07-fa21c51abe3a"
   },
   "outputs": [],
   "source": [
    "df1 = data1.copy()\n",
    "df2 = data2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e93d157c-2a09-4aa4-8a84-e6ea13cbf03b",
   "metadata": {
    "id": "e93d157c-2a09-4aa4-8a84-e6ea13cbf03b"
   },
   "outputs": [],
   "source": [
    "# overview of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12ab5ac3-db06-40aa-9026-4fe63c16353c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12ab5ac3-db06-40aa-9026-4fe63c16353c",
    "outputId": "26c11e90-93cc-42a7-8cbf-184e28d24cef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51336 entries, 0 to 51335\n",
      "Data columns (total 26 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   PROSPECTID            51336 non-null  int64  \n",
      " 1   Total_TL              51336 non-null  int64  \n",
      " 2   Tot_Closed_TL         51336 non-null  int64  \n",
      " 3   Tot_Active_TL         51336 non-null  int64  \n",
      " 4   Total_TL_opened_L6M   51336 non-null  int64  \n",
      " 5   Tot_TL_closed_L6M     51336 non-null  int64  \n",
      " 6   pct_tl_open_L6M       51336 non-null  float64\n",
      " 7   pct_tl_closed_L6M     51336 non-null  float64\n",
      " 8   pct_active_tl         51336 non-null  float64\n",
      " 9   pct_closed_tl         51336 non-null  float64\n",
      " 10  Total_TL_opened_L12M  51336 non-null  int64  \n",
      " 11  Tot_TL_closed_L12M    51336 non-null  int64  \n",
      " 12  pct_tl_open_L12M      51336 non-null  float64\n",
      " 13  pct_tl_closed_L12M    51336 non-null  float64\n",
      " 14  Tot_Missed_Pmnt       51336 non-null  int64  \n",
      " 15  Auto_TL               51336 non-null  int64  \n",
      " 16  CC_TL                 51336 non-null  int64  \n",
      " 17  Consumer_TL           51336 non-null  int64  \n",
      " 18  Gold_TL               51336 non-null  int64  \n",
      " 19  Home_TL               51336 non-null  int64  \n",
      " 20  PL_TL                 51336 non-null  int64  \n",
      " 21  Secured_TL            51336 non-null  int64  \n",
      " 22  Unsecured_TL          51336 non-null  int64  \n",
      " 23  Other_TL              51336 non-null  int64  \n",
      " 24  Age_Oldest_TL         51336 non-null  int64  \n",
      " 25  Age_Newest_TL         51336 non-null  int64  \n",
      "dtypes: float64(6), int64(20)\n",
      "memory usage: 10.2 MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d9bc838-24f3-450e-9d77-f5c100b50ac3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d9bc838-24f3-450e-9d77-f5c100b50ac3",
    "outputId": "c52be8e9-ba36-442e-b1ce-6e1e758e990b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51336 entries, 0 to 51335\n",
      "Data columns (total 62 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   PROSPECTID                    51336 non-null  int64  \n",
      " 1   time_since_recent_payment     51336 non-null  int64  \n",
      " 2   time_since_first_deliquency   51336 non-null  int64  \n",
      " 3   time_since_recent_deliquency  51336 non-null  int64  \n",
      " 4   num_times_delinquent          51336 non-null  int64  \n",
      " 5   max_delinquency_level         51336 non-null  int64  \n",
      " 6   max_recent_level_of_deliq     51336 non-null  int64  \n",
      " 7   num_deliq_6mts                51336 non-null  int64  \n",
      " 8   num_deliq_12mts               51336 non-null  int64  \n",
      " 9   num_deliq_6_12mts             51336 non-null  int64  \n",
      " 10  max_deliq_6mts                51336 non-null  int64  \n",
      " 11  max_deliq_12mts               51336 non-null  int64  \n",
      " 12  num_times_30p_dpd             51336 non-null  int64  \n",
      " 13  num_times_60p_dpd             51336 non-null  int64  \n",
      " 14  num_std                       51336 non-null  int64  \n",
      " 15  num_std_6mts                  51336 non-null  int64  \n",
      " 16  num_std_12mts                 51336 non-null  int64  \n",
      " 17  num_sub                       51336 non-null  int64  \n",
      " 18  num_sub_6mts                  51336 non-null  int64  \n",
      " 19  num_sub_12mts                 51336 non-null  int64  \n",
      " 20  num_dbt                       51336 non-null  int64  \n",
      " 21  num_dbt_6mts                  51336 non-null  int64  \n",
      " 22  num_dbt_12mts                 51336 non-null  int64  \n",
      " 23  num_lss                       51336 non-null  int64  \n",
      " 24  num_lss_6mts                  51336 non-null  int64  \n",
      " 25  num_lss_12mts                 51336 non-null  int64  \n",
      " 26  recent_level_of_deliq         51336 non-null  int64  \n",
      " 27  tot_enq                       51336 non-null  int64  \n",
      " 28  CC_enq                        51336 non-null  int64  \n",
      " 29  CC_enq_L6m                    51336 non-null  int64  \n",
      " 30  CC_enq_L12m                   51336 non-null  int64  \n",
      " 31  PL_enq                        51336 non-null  int64  \n",
      " 32  PL_enq_L6m                    51336 non-null  int64  \n",
      " 33  PL_enq_L12m                   51336 non-null  int64  \n",
      " 34  time_since_recent_enq         51336 non-null  int64  \n",
      " 35  enq_L12m                      51336 non-null  int64  \n",
      " 36  enq_L6m                       51336 non-null  int64  \n",
      " 37  enq_L3m                       51336 non-null  int64  \n",
      " 38  MARITALSTATUS                 51336 non-null  object \n",
      " 39  EDUCATION                     51336 non-null  object \n",
      " 40  AGE                           51336 non-null  int64  \n",
      " 41  GENDER                        51336 non-null  object \n",
      " 42  NETMONTHLYINCOME              51336 non-null  int64  \n",
      " 43  Time_With_Curr_Empr           51336 non-null  int64  \n",
      " 44  pct_of_active_TLs_ever        51336 non-null  float64\n",
      " 45  pct_opened_TLs_L6m_of_L12m    51336 non-null  float64\n",
      " 46  pct_currentBal_all_TL         51336 non-null  float64\n",
      " 47  CC_utilization                51336 non-null  float64\n",
      " 48  CC_Flag                       51336 non-null  int64  \n",
      " 49  PL_utilization                51336 non-null  float64\n",
      " 50  PL_Flag                       51336 non-null  int64  \n",
      " 51  pct_PL_enq_L6m_of_L12m        51336 non-null  float64\n",
      " 52  pct_CC_enq_L6m_of_L12m        51336 non-null  float64\n",
      " 53  pct_PL_enq_L6m_of_ever        51336 non-null  float64\n",
      " 54  pct_CC_enq_L6m_of_ever        51336 non-null  float64\n",
      " 55  max_unsec_exposure_inPct      51336 non-null  float64\n",
      " 56  HL_Flag                       51336 non-null  int64  \n",
      " 57  GL_Flag                       51336 non-null  int64  \n",
      " 58  last_prod_enq2                51336 non-null  object \n",
      " 59  first_prod_enq2               51336 non-null  object \n",
      " 60  Credit_Score                  51336 non-null  int64  \n",
      " 61  Approved_Flag                 51336 non-null  object \n",
      "dtypes: float64(10), int64(46), object(6)\n",
      "memory usage: 24.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d937d9e-bc36-4bcf-9797-155a74eceaf9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d937d9e-bc36-4bcf-9797-155a74eceaf9",
    "outputId": "5d9ba240-f76e-4cb8-ae18-232a57034132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51336, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(51336, 62)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26e518e1-394e-421a-9088-dd5c69b28ce1",
   "metadata": {
    "id": "26e518e1-394e-421a-9088-dd5c69b28ce1"
   },
   "outputs": [],
   "source": [
    "# feature / variable overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0222e9a-ddd7-48c2-a88a-87f11c0ce090",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "a0222e9a-ddd7-48c2-a88a-87f11c0ce090",
    "outputId": "ce8cdf32-4e2d-45ef-ac9e-d3806349685d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        P2\n",
       "1        P2\n",
       "2        P2\n",
       "3        P2\n",
       "4        P1\n",
       "         ..\n",
       "51331    P4\n",
       "51332    P1\n",
       "51333    P3\n",
       "51334    P2\n",
       "51335    P2\n",
       "Name: Approved_Flag, Length: 51336, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Approved_Flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b77d83b-4ddc-47b2-a1b7-9680e9d9786c",
   "metadata": {
    "id": "5b77d83b-4ddc-47b2-a1b7-9680e9d9786c"
   },
   "source": [
    "will be here later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "206ba765-e54d-47d8-8101-c0197c8dcbc0",
   "metadata": {
    "id": "206ba765-e54d-47d8-8101-c0197c8dcbc0"
   },
   "outputs": [],
   "source": [
    "# Here we can see we do not have any null values. But we have lets see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "255e1933-14b6-4e40-94b6-fc43be085c83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "255e1933-14b6-4e40-94b6-fc43be085c83",
    "outputId": "07e68f18-98e3-48c1-dc4d-be032601f194",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROSPECTID</th>\n",
       "      <th>Total_TL</th>\n",
       "      <th>Tot_Closed_TL</th>\n",
       "      <th>Tot_Active_TL</th>\n",
       "      <th>Total_TL_opened_L6M</th>\n",
       "      <th>Tot_TL_closed_L6M</th>\n",
       "      <th>pct_tl_open_L6M</th>\n",
       "      <th>pct_tl_closed_L6M</th>\n",
       "      <th>pct_active_tl</th>\n",
       "      <th>pct_closed_tl</th>\n",
       "      <th>...</th>\n",
       "      <th>CC_TL</th>\n",
       "      <th>Consumer_TL</th>\n",
       "      <th>Gold_TL</th>\n",
       "      <th>Home_TL</th>\n",
       "      <th>PL_TL</th>\n",
       "      <th>Secured_TL</th>\n",
       "      <th>Unsecured_TL</th>\n",
       "      <th>Other_TL</th>\n",
       "      <th>Age_Oldest_TL</th>\n",
       "      <th>Age_Newest_TL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>533</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>1180</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5694</th>\n",
       "      <td>5695</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>5952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9079</th>\n",
       "      <td>9080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10859</th>\n",
       "      <td>10860</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12017</th>\n",
       "      <td>12018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12478</th>\n",
       "      <td>12479</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12603</th>\n",
       "      <td>12604</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15248</th>\n",
       "      <td>15249</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16903</th>\n",
       "      <td>16904</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21698</th>\n",
       "      <td>21699</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22649</th>\n",
       "      <td>22650</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23272</th>\n",
       "      <td>23273</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24409</th>\n",
       "      <td>24410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25778</th>\n",
       "      <td>25779</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26228</th>\n",
       "      <td>26229</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28495</th>\n",
       "      <td>28496</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29034</th>\n",
       "      <td>29035</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29838</th>\n",
       "      <td>29839</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29900</th>\n",
       "      <td>29901</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30732</th>\n",
       "      <td>30733</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32048</th>\n",
       "      <td>32049</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33012</th>\n",
       "      <td>33013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34897</th>\n",
       "      <td>34898</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36155</th>\n",
       "      <td>36156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36705</th>\n",
       "      <td>36706</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37908</th>\n",
       "      <td>37909</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39097</th>\n",
       "      <td>39098</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39747</th>\n",
       "      <td>39748</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41266</th>\n",
       "      <td>41267</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42863</th>\n",
       "      <td>42864</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45680</th>\n",
       "      <td>45681</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46777</th>\n",
       "      <td>46778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46954</th>\n",
       "      <td>46955</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50291</th>\n",
       "      <td>50292</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50804</th>\n",
       "      <td>50805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PROSPECTID  Total_TL  Tot_Closed_TL  Tot_Active_TL  \\\n",
       "532           533         2              2              0   \n",
       "804           805         1              0              1   \n",
       "1179         1180         1              0              1   \n",
       "3299         3300         1              1              0   \n",
       "5694         5695         1              0              1   \n",
       "5951         5952         1              0              1   \n",
       "9079         9080         1              0              1   \n",
       "10003       10004         1              0              1   \n",
       "10859       10860         1              0              1   \n",
       "12017       12018         1              0              1   \n",
       "12478       12479         1              0              1   \n",
       "12603       12604         1              0              1   \n",
       "15248       15249         1              0              1   \n",
       "16903       16904         1              0              1   \n",
       "21698       21699         1              0              1   \n",
       "22649       22650         1              1              0   \n",
       "23272       23273         1              1              0   \n",
       "24409       24410         1              0              1   \n",
       "25778       25779         1              0              1   \n",
       "26228       26229         1              0              1   \n",
       "28495       28496         1              0              1   \n",
       "29034       29035         1              0              1   \n",
       "29838       29839         1              0              1   \n",
       "29900       29901         1              0              1   \n",
       "30732       30733         1              0              1   \n",
       "32048       32049         1              1              0   \n",
       "33012       33013         1              0              1   \n",
       "34897       34898         1              0              1   \n",
       "36155       36156         1              0              1   \n",
       "36705       36706         1              0              1   \n",
       "37908       37909         1              0              1   \n",
       "39097       39098         1              0              1   \n",
       "39747       39748         1              0              1   \n",
       "41266       41267         1              1              0   \n",
       "42863       42864         1              0              1   \n",
       "45680       45681         6              6              0   \n",
       "46777       46778         1              0              1   \n",
       "46954       46955         1              0              1   \n",
       "50291       50292         2              0              2   \n",
       "50804       50805         1              0              1   \n",
       "\n",
       "       Total_TL_opened_L6M  Tot_TL_closed_L6M  pct_tl_open_L6M  \\\n",
       "532                      0                  0              0.0   \n",
       "804                      0                  0              0.0   \n",
       "1179                     0                  0              0.0   \n",
       "3299                     0                  0              0.0   \n",
       "5694                     0                  0              0.0   \n",
       "5951                     0                  0              0.0   \n",
       "9079                     0                  0              0.0   \n",
       "10003                    0                  0              0.0   \n",
       "10859                    0                  0              0.0   \n",
       "12017                    0                  0              0.0   \n",
       "12478                    0                  0              0.0   \n",
       "12603                    0                  0              0.0   \n",
       "15248                    0                  0              0.0   \n",
       "16903                    0                  0              0.0   \n",
       "21698                    0                  0              0.0   \n",
       "22649                    0                  0              0.0   \n",
       "23272                    0                  0              0.0   \n",
       "24409                    0                  0              0.0   \n",
       "25778                    0                  0              0.0   \n",
       "26228                    0                  0              0.0   \n",
       "28495                    0                  0              0.0   \n",
       "29034                    0                  0              0.0   \n",
       "29838                    0                  0              0.0   \n",
       "29900                    0                  0              0.0   \n",
       "30732                    0                  0              0.0   \n",
       "32048                    0                  0              0.0   \n",
       "33012                    0                  0              0.0   \n",
       "34897                    0                  0              0.0   \n",
       "36155                    0                  0              0.0   \n",
       "36705                    0                  0              0.0   \n",
       "37908                    0                  0              0.0   \n",
       "39097                    0                  0              0.0   \n",
       "39747                    0                  0              0.0   \n",
       "41266                    0                  0              0.0   \n",
       "42863                    0                  0              0.0   \n",
       "45680                    0                  0              0.0   \n",
       "46777                    0                  0              0.0   \n",
       "46954                    0                  0              0.0   \n",
       "50291                    0                  0              0.0   \n",
       "50804                    0                  0              0.0   \n",
       "\n",
       "       pct_tl_closed_L6M  pct_active_tl  pct_closed_tl  ...  CC_TL  \\\n",
       "532                  0.0            0.0            1.0  ...      0   \n",
       "804                  0.0            1.0            0.0  ...      0   \n",
       "1179                 0.0            1.0            0.0  ...      0   \n",
       "3299                 0.0            0.0            1.0  ...      0   \n",
       "5694                 0.0            1.0            0.0  ...      0   \n",
       "5951                 0.0            1.0            0.0  ...      0   \n",
       "9079                 0.0            1.0            0.0  ...      0   \n",
       "10003                0.0            1.0            0.0  ...      0   \n",
       "10859                0.0            1.0            0.0  ...      0   \n",
       "12017                0.0            1.0            0.0  ...      0   \n",
       "12478                0.0            1.0            0.0  ...      0   \n",
       "12603                0.0            1.0            0.0  ...      0   \n",
       "15248                0.0            1.0            0.0  ...      0   \n",
       "16903                0.0            1.0            0.0  ...      0   \n",
       "21698                0.0            1.0            0.0  ...      0   \n",
       "22649                0.0            0.0            1.0  ...      0   \n",
       "23272                0.0            0.0            1.0  ...      0   \n",
       "24409                0.0            1.0            0.0  ...      0   \n",
       "25778                0.0            1.0            0.0  ...      0   \n",
       "26228                0.0            1.0            0.0  ...      0   \n",
       "28495                0.0            1.0            0.0  ...      0   \n",
       "29034                0.0            1.0            0.0  ...      0   \n",
       "29838                0.0            1.0            0.0  ...      0   \n",
       "29900                0.0            1.0            0.0  ...      0   \n",
       "30732                0.0            1.0            0.0  ...      0   \n",
       "32048                0.0            0.0            1.0  ...      0   \n",
       "33012                0.0            1.0            0.0  ...      0   \n",
       "34897                0.0            1.0            0.0  ...      0   \n",
       "36155                0.0            1.0            0.0  ...      0   \n",
       "36705                0.0            1.0            0.0  ...      0   \n",
       "37908                0.0            1.0            0.0  ...      0   \n",
       "39097                0.0            1.0            0.0  ...      0   \n",
       "39747                0.0            1.0            0.0  ...      0   \n",
       "41266                0.0            0.0            1.0  ...      0   \n",
       "42863                0.0            1.0            0.0  ...      0   \n",
       "45680                0.0            0.0            1.0  ...      0   \n",
       "46777                0.0            1.0            0.0  ...      0   \n",
       "46954                0.0            1.0            0.0  ...      0   \n",
       "50291                0.0            1.0            0.0  ...      0   \n",
       "50804                0.0            1.0            0.0  ...      0   \n",
       "\n",
       "       Consumer_TL  Gold_TL  Home_TL  PL_TL  Secured_TL  Unsecured_TL  \\\n",
       "532              0        0        0      0           2             0   \n",
       "804              0        0        0      0           0             1   \n",
       "1179             0        1        0      0           1             0   \n",
       "3299             0        0        0      0           0             1   \n",
       "5694             0        0        0      0           0             1   \n",
       "5951             0        0        0      0           0             1   \n",
       "9079             0        0        0      0           0             1   \n",
       "10003            0        0        0      0           0             1   \n",
       "10859            0        0        0      0           1             0   \n",
       "12017            0        0        0      0           0             1   \n",
       "12478            0        0        0      0           0             1   \n",
       "12603            0        0        0      0           0             1   \n",
       "15248            0        0        0      0           0             1   \n",
       "16903            0        0        0      0           0             1   \n",
       "21698            0        0        0      0           0             1   \n",
       "22649            0        0        0      0           1             0   \n",
       "23272            0        0        0      0           1             0   \n",
       "24409            0        0        0      0           0             1   \n",
       "25778            0        0        0      0           0             1   \n",
       "26228            0        0        0      0           0             1   \n",
       "28495            0        0        1      0           1             0   \n",
       "29034            0        0        0      0           0             1   \n",
       "29838            0        0        0      0           0             1   \n",
       "29900            0        0        0      0           0             1   \n",
       "30732            0        0        0      0           0             1   \n",
       "32048            0        0        0      0           1             0   \n",
       "33012            0        0        0      0           0             1   \n",
       "34897            0        0        0      0           0             1   \n",
       "36155            0        0        0      0           0             1   \n",
       "36705            0        0        0      1           0             1   \n",
       "37908            0        0        0      0           0             1   \n",
       "39097            0        0        0      0           1             0   \n",
       "39747            0        0        0      0           0             1   \n",
       "41266            0        0        0      0           1             0   \n",
       "42863            0        0        0      0           0             1   \n",
       "45680            0        0        0      0           6             0   \n",
       "46777            0        0        0      0           1             0   \n",
       "46954            0        0        0      0           0             1   \n",
       "50291            0        0        0      0           2             0   \n",
       "50804            0        0        0      0           0             1   \n",
       "\n",
       "       Other_TL  Age_Oldest_TL  Age_Newest_TL  \n",
       "532           2         -99999         -99999  \n",
       "804           1         -99999         -99999  \n",
       "1179          0         -99999         -99999  \n",
       "3299          1         -99999         -99999  \n",
       "5694          1         -99999         -99999  \n",
       "5951          1         -99999         -99999  \n",
       "9079          1         -99999         -99999  \n",
       "10003         1         -99999         -99999  \n",
       "10859         1         -99999         -99999  \n",
       "12017         1         -99999         -99999  \n",
       "12478         1         -99999         -99999  \n",
       "12603         1         -99999         -99999  \n",
       "15248         1         -99999         -99999  \n",
       "16903         1         -99999         -99999  \n",
       "21698         1         -99999         -99999  \n",
       "22649         1         -99999         -99999  \n",
       "23272         1         -99999         -99999  \n",
       "24409         1         -99999         -99999  \n",
       "25778         1         -99999         -99999  \n",
       "26228         1         -99999         -99999  \n",
       "28495         0         -99999         -99999  \n",
       "29034         1         -99999         -99999  \n",
       "29838         1         -99999         -99999  \n",
       "29900         1         -99999         -99999  \n",
       "30732         1         -99999         -99999  \n",
       "32048         1         -99999         -99999  \n",
       "33012         1         -99999         -99999  \n",
       "34897         1         -99999         -99999  \n",
       "36155         1         -99999         -99999  \n",
       "36705         0         -99999         -99999  \n",
       "37908         1         -99999         -99999  \n",
       "39097         1         -99999         -99999  \n",
       "39747         1         -99999         -99999  \n",
       "41266         0         -99999         -99999  \n",
       "42863         1         -99999         -99999  \n",
       "45680         6         -99999         -99999  \n",
       "46777         1         -99999         -99999  \n",
       "46954         1         -99999         -99999  \n",
       "50291         2         -99999         -99999  \n",
       "50804         1         -99999         -99999  \n",
       "\n",
       "[40 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['Age_Oldest_TL'] == -99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ea33707-68f4-41bd-b9d4-c560f609486f",
   "metadata": {
    "id": "1ea33707-68f4-41bd-b9d4-c560f609486f"
   },
   "outputs": [],
   "source": [
    "# Here we have multiple -99999 values in our data ,this is the null value in our data set which is filled by -99999 number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e66c06-0e49-4283-a789-bc8990014953",
   "metadata": {
    "id": "02e66c06-0e49-4283-a789-bc8990014953"
   },
   "outputs": [],
   "source": [
    "# so what we will do either we will fill or remove the null values .\n",
    "# But we will not fill values since i don;t have much domain knowledge i will drop the null values\n",
    "# and if we have 40000 or greater than 40000 rows then we will go further if not we will try to fill the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e13d0b15-3c9e-42df-91b0-62d7e960e1df",
   "metadata": {
    "id": "e13d0b15-3c9e-42df-91b0-62d7e960e1df"
   },
   "outputs": [],
   "source": [
    "df1 = df1.loc[df1['Age_Oldest_TL'] != -99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af16da27-b00b-441f-8092-58c0a5af9cce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af16da27-b00b-441f-8092-58c0a5af9cce",
    "outputId": "9dbe081c-dbe5-4e4a-c0b8-56a82ad700ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROSPECTID --> 0\n",
      "Total_TL --> 0\n",
      "Tot_Closed_TL --> 0\n",
      "Tot_Active_TL --> 0\n",
      "Total_TL_opened_L6M --> 0\n",
      "Tot_TL_closed_L6M --> 0\n",
      "pct_tl_open_L6M --> 0\n",
      "pct_tl_closed_L6M --> 0\n",
      "pct_active_tl --> 0\n",
      "pct_closed_tl --> 0\n",
      "Total_TL_opened_L12M --> 0\n",
      "Tot_TL_closed_L12M --> 0\n",
      "pct_tl_open_L12M --> 0\n",
      "pct_tl_closed_L12M --> 0\n",
      "Tot_Missed_Pmnt --> 0\n",
      "Auto_TL --> 0\n",
      "CC_TL --> 0\n",
      "Consumer_TL --> 0\n",
      "Gold_TL --> 0\n",
      "Home_TL --> 0\n",
      "PL_TL --> 0\n",
      "Secured_TL --> 0\n",
      "Unsecured_TL --> 0\n",
      "Other_TL --> 0\n",
      "Age_Oldest_TL --> 0\n",
      "Age_Newest_TL --> 0\n"
     ]
    }
   ],
   "source": [
    "for col in df1.columns:\n",
    "    print(f'{col} --> {df1[df1[col] == -99999].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e16e6df0-b2bf-4c32-99a9-b110e893bef9",
   "metadata": {
    "id": "e16e6df0-b2bf-4c32-99a9-b110e893bef9"
   },
   "outputs": [],
   "source": [
    "columns_to_drop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b564622c-3c29-4c23-848b-dd2c947f4ee5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b564622c-3c29-4c23-848b-dd2c947f4ee5",
    "outputId": "ec193a6b-2b6c-4311-b9fd-af8fccce5bc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROSPECTID --> 0\n",
      "time_since_recent_payment --> 4291\n",
      "time_since_first_deliquency --> 35949\n",
      "time_since_recent_deliquency --> 35949\n",
      "num_times_delinquent --> 0\n",
      "max_delinquency_level --> 35949\n",
      "max_recent_level_of_deliq --> 0\n",
      "num_deliq_6mts --> 0\n",
      "num_deliq_12mts --> 0\n",
      "num_deliq_6_12mts --> 0\n",
      "max_deliq_6mts --> 12890\n",
      "max_deliq_12mts --> 10832\n",
      "num_times_30p_dpd --> 0\n",
      "num_times_60p_dpd --> 0\n",
      "num_std --> 0\n",
      "num_std_6mts --> 0\n",
      "num_std_12mts --> 0\n",
      "num_sub --> 0\n",
      "num_sub_6mts --> 0\n",
      "num_sub_12mts --> 0\n",
      "num_dbt --> 0\n",
      "num_dbt_6mts --> 0\n",
      "num_dbt_12mts --> 0\n",
      "num_lss --> 0\n",
      "num_lss_6mts --> 0\n",
      "num_lss_12mts --> 0\n",
      "recent_level_of_deliq --> 0\n",
      "tot_enq --> 6321\n",
      "CC_enq --> 6321\n",
      "CC_enq_L6m --> 6321\n",
      "CC_enq_L12m --> 6321\n",
      "PL_enq --> 6321\n",
      "PL_enq_L6m --> 6321\n",
      "PL_enq_L12m --> 6321\n",
      "time_since_recent_enq --> 6321\n",
      "enq_L12m --> 6321\n",
      "enq_L6m --> 6321\n",
      "enq_L3m --> 6321\n",
      "MARITALSTATUS --> 0\n",
      "EDUCATION --> 0\n",
      "AGE --> 0\n",
      "GENDER --> 0\n",
      "NETMONTHLYINCOME --> 0\n",
      "Time_With_Curr_Empr --> 0\n",
      "pct_of_active_TLs_ever --> 0\n",
      "pct_opened_TLs_L6m_of_L12m --> 0\n",
      "pct_currentBal_all_TL --> 72\n",
      "CC_utilization --> 47636\n",
      "CC_Flag --> 0\n",
      "PL_utilization --> 44435\n",
      "PL_Flag --> 0\n",
      "pct_PL_enq_L6m_of_L12m --> 0\n",
      "pct_CC_enq_L6m_of_L12m --> 0\n",
      "pct_PL_enq_L6m_of_ever --> 0\n",
      "pct_CC_enq_L6m_of_ever --> 0\n",
      "max_unsec_exposure_inPct --> 23178\n",
      "HL_Flag --> 0\n",
      "GL_Flag --> 0\n",
      "last_prod_enq2 --> 0\n",
      "first_prod_enq2 --> 0\n",
      "Credit_Score --> 0\n",
      "Approved_Flag --> 0\n"
     ]
    }
   ],
   "source": [
    "for col in df2.columns:\n",
    "    print(f'{col} --> {df2[df2[col] == -99999].shape[0]}')\n",
    "    if df2[df2[col] == -99999].shape[0] > 10000:\n",
    "        columns_to_drop.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e4247b1-7192-415c-83be-00ef8a790ee1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e4247b1-7192-415c-83be-00ef8a790ee1",
    "outputId": "f8e2380c-bb6b-45fd-9c5c-703f23940cd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_since_first_deliquency',\n",
       " 'time_since_recent_deliquency',\n",
       " 'max_delinquency_level',\n",
       " 'max_deliq_6mts',\n",
       " 'max_deliq_12mts',\n",
       " 'CC_utilization',\n",
       " 'PL_utilization',\n",
       " 'max_unsec_exposure_inPct']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b77ee48-4355-4573-bf0c-f5991f25de5e",
   "metadata": {
    "id": "4b77ee48-4355-4573-bf0c-f5991f25de5e"
   },
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns=columns_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c19b9522-ad3f-42dd-afc5-71b323b3d9b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c19b9522-ad3f-42dd-afc5-71b323b3d9b7",
    "outputId": "df23aa75-7f6d-437e-bd3c-92b1f6e91a38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51336, 54)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cceaec3-7be4-46ca-9e65-139996a55803",
   "metadata": {
    "id": "6cceaec3-7be4-46ca-9e65-139996a55803"
   },
   "outputs": [],
   "source": [
    "for col in df2.columns:\n",
    "    df2 = df2.loc[df2[col] != -99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "991dc978-4bcc-48e6-9dee-d8015d64e289",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "991dc978-4bcc-48e6-9dee-d8015d64e289",
    "outputId": "acac72ea-d1c8-4a3d-fd5b-0c6d1fe019ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42066, 54)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dec10362-f9a5-4409-a067-153518976c7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dec10362-f9a5-4409-a067-153518976c7a",
    "outputId": "d733d9ac-e8fb-406e-ce73-f57f0f7b0a56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d610dae-67d9-4764-bcfd-dc8dbf45340c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d610dae-67d9-4764-bcfd-dc8dbf45340c",
    "outputId": "d177342d-efed-4c62-fa65-0e577a199ee8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ca53e20-b687-49f5-b265-697bf1f3d472",
   "metadata": {
    "id": "7ca53e20-b687-49f5-b265-697bf1f3d472"
   },
   "outputs": [],
   "source": [
    "# Now i droped all the null values and i will go further if we have more than 40000 rows so we have 42000 rows, so i will go without hesitating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6617b5b-06b8-46a8-a7d8-59a6987a2377",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6617b5b-06b8-46a8-a7d8-59a6987a2377",
    "outputId": "a6187c46-7f96-4e32-d121-111713fe75e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROSPECTID\n"
     ]
    }
   ],
   "source": [
    "for i in list(df1.columns):\n",
    "    if i in list(df2.columns):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc68c169-d7fc-408b-a6f0-bf52661ed303",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "dc68c169-d7fc-408b-a6f0-bf52661ed303",
    "outputId": "ee8f3010-9370-4750-89e0-003f7c966a4d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROSPECTID</th>\n",
       "      <th>Total_TL</th>\n",
       "      <th>Tot_Closed_TL</th>\n",
       "      <th>Tot_Active_TL</th>\n",
       "      <th>Total_TL_opened_L6M</th>\n",
       "      <th>Tot_TL_closed_L6M</th>\n",
       "      <th>pct_tl_open_L6M</th>\n",
       "      <th>pct_tl_closed_L6M</th>\n",
       "      <th>pct_active_tl</th>\n",
       "      <th>pct_closed_tl</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_PL_enq_L6m_of_L12m</th>\n",
       "      <th>pct_CC_enq_L6m_of_L12m</th>\n",
       "      <th>pct_PL_enq_L6m_of_ever</th>\n",
       "      <th>pct_CC_enq_L6m_of_ever</th>\n",
       "      <th>HL_Flag</th>\n",
       "      <th>GL_Flag</th>\n",
       "      <th>last_prod_enq2</th>\n",
       "      <th>first_prod_enq2</th>\n",
       "      <th>Credit_Score</th>\n",
       "      <th>Approved_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PL</td>\n",
       "      <td>PL</td>\n",
       "      <td>696</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ConsumerLoan</td>\n",
       "      <td>ConsumerLoan</td>\n",
       "      <td>685</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ConsumerLoan</td>\n",
       "      <td>others</td>\n",
       "      <td>693</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "      <td>AL</td>\n",
       "      <td>753</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.833</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ConsumerLoan</td>\n",
       "      <td>PL</td>\n",
       "      <td>668</td>\n",
       "      <td>P3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROSPECTID  Total_TL  Tot_Closed_TL  Tot_Active_TL  Total_TL_opened_L6M  \\\n",
       "0           1         5              4              1                    0   \n",
       "1           2         1              0              1                    0   \n",
       "2           3         8              0              8                    1   \n",
       "3           5         3              2              1                    0   \n",
       "4           6         6              5              1                    0   \n",
       "\n",
       "   Tot_TL_closed_L6M  pct_tl_open_L6M  pct_tl_closed_L6M  pct_active_tl  \\\n",
       "0                  0            0.000                0.0          0.200   \n",
       "1                  0            0.000                0.0          1.000   \n",
       "2                  0            0.125                0.0          1.000   \n",
       "3                  0            0.000                0.0          0.333   \n",
       "4                  0            0.000                0.0          0.167   \n",
       "\n",
       "   pct_closed_tl  ...  pct_PL_enq_L6m_of_L12m  pct_CC_enq_L6m_of_L12m  \\\n",
       "0          0.800  ...                     0.0                     0.0   \n",
       "1          0.000  ...                     0.0                     0.0   \n",
       "2          0.000  ...                     0.0                     0.0   \n",
       "3          0.667  ...                     0.0                     0.0   \n",
       "4          0.833  ...                     1.0                     0.0   \n",
       "\n",
       "   pct_PL_enq_L6m_of_ever  pct_CC_enq_L6m_of_ever  HL_Flag  GL_Flag  \\\n",
       "0                   0.000                     0.0        1        0   \n",
       "1                   0.000                     0.0        0        0   \n",
       "2                   0.000                     0.0        1        0   \n",
       "3                   0.000                     0.0        0        0   \n",
       "4                   0.429                     0.0        1        0   \n",
       "\n",
       "   last_prod_enq2  first_prod_enq2  Credit_Score  Approved_Flag  \n",
       "0              PL               PL           696             P2  \n",
       "1    ConsumerLoan     ConsumerLoan           685             P2  \n",
       "2    ConsumerLoan           others           693             P2  \n",
       "3              AL               AL           753             P1  \n",
       "4    ConsumerLoan               PL           668             P3  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df1.merge(df2,on='PROSPECTID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d712f6ac-9a40-4f8a-a428-bd8cb3c83ce9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d712f6ac-9a40-4f8a-a428-bd8cb3c83ce9",
    "outputId": "094d8edc-6a09-4159-c275-7de335244175"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42064, 79)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4812f338-5e6d-4428-b193-612d6eefec63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4812f338-5e6d-4428-b193-612d6eefec63",
    "outputId": "588c93db-bea3-4bd2-9caf-1cdbb2dd1260"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99a6dee9-e1e4-4bb3-b86f-5ec0d414da92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "99a6dee9-e1e4-4bb3-b86f-5ec0d414da92",
    "outputId": "fb52f2de-6504-46ca-ce54-ae6bb5326ffa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        P2\n",
       "1        P2\n",
       "2        P2\n",
       "3        P1\n",
       "4        P3\n",
       "         ..\n",
       "42059    P4\n",
       "42060    P1\n",
       "42061    P3\n",
       "42062    P2\n",
       "42063    P2\n",
       "Name: Approved_Flag, Length: 42064, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Approved_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "379c899c-d327-438b-9440-0e685a14b018",
   "metadata": {
    "id": "379c899c-d327-438b-9440-0e685a14b018"
   },
   "outputs": [],
   "source": [
    "# check how many categorical columns we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "894d40ff-eabf-4a78-a212-0a8bf73707aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "894d40ff-eabf-4a78-a212-0a8bf73707aa",
    "outputId": "24f99111-cc77-4381-cb60-cac440175d2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2',\n",
       "       'first_prod_enq2', 'Approved_Flag'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include='O').columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b63a4f0-aac0-4a90-b389-08ef2105dac7",
   "metadata": {
    "id": "2b63a4f0-aac0-4a90-b389-08ef2105dac7"
   },
   "outputs": [],
   "source": [
    "categorical_column = ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2','first_prod_enq2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8879b2bf-5e64-4112-afdd-7429e2536f4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8879b2bf-5e64-4112-afdd-7429e2536f4b",
    "outputId": "e28768f5-dde1-4750-901a-827ffd99a6e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS --> 3.578180861038862e-233\n",
      "EDUCATION --> 2.6942265249737532e-30\n",
      "GENDER --> 1.907936100186563e-05\n",
      "last_prod_enq2 --> 0.0\n",
      "first_prod_enq2 --> 7.84997610555419e-287\n"
     ]
    }
   ],
   "source": [
    "for i in categorical_column:\n",
    "    chi_,p_value,_,_ = chi2_contingency(pd.crosstab(df[i] , df['Approved_Flag']))\n",
    "    print(f'{i} --> {p_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16fc1a6e-5215-4d17-9036-5814110ebb9b",
   "metadata": {
    "id": "16fc1a6e-5215-4d17-9036-5814110ebb9b"
   },
   "outputs": [],
   "source": [
    "# All column have p_values less than 0.05 . we will accept all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8535fb2e-0609-4355-9902-33655647111d",
   "metadata": {
    "id": "8535fb2e-0609-4355-9902-33655647111d"
   },
   "outputs": [],
   "source": [
    "numerical_column = []\n",
    "for i in df.columns:\n",
    "    if df[i].name not in (df.select_dtypes(include='O').columns):\n",
    "        numerical_column.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6725745-939e-4a8d-9f17-64bbd75d537f",
   "metadata": {
    "id": "f6725745-939e-4a8d-9f17-64bbd75d537f"
   },
   "outputs": [],
   "source": [
    "numerical_column.remove('PROSPECTID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "973c0605-2d0d-45e2-840a-18d29f3dda68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "973c0605-2d0d-45e2-840a-18d29f3dda68",
    "outputId": "462689af-9c0d-496f-d209-c935f0b46dfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Total_TL',\n",
       " 'Tot_Closed_TL',\n",
       " 'Tot_Active_TL',\n",
       " 'Total_TL_opened_L6M',\n",
       " 'Tot_TL_closed_L6M',\n",
       " 'pct_tl_open_L6M',\n",
       " 'pct_tl_closed_L6M',\n",
       " 'pct_active_tl',\n",
       " 'pct_closed_tl',\n",
       " 'Total_TL_opened_L12M',\n",
       " 'Tot_TL_closed_L12M',\n",
       " 'pct_tl_open_L12M',\n",
       " 'pct_tl_closed_L12M',\n",
       " 'Tot_Missed_Pmnt',\n",
       " 'Auto_TL',\n",
       " 'CC_TL',\n",
       " 'Consumer_TL',\n",
       " 'Gold_TL',\n",
       " 'Home_TL',\n",
       " 'PL_TL',\n",
       " 'Secured_TL',\n",
       " 'Unsecured_TL',\n",
       " 'Other_TL',\n",
       " 'Age_Oldest_TL',\n",
       " 'Age_Newest_TL',\n",
       " 'time_since_recent_payment',\n",
       " 'num_times_delinquent',\n",
       " 'max_recent_level_of_deliq',\n",
       " 'num_deliq_6mts',\n",
       " 'num_deliq_12mts',\n",
       " 'num_deliq_6_12mts',\n",
       " 'num_times_30p_dpd',\n",
       " 'num_times_60p_dpd',\n",
       " 'num_std',\n",
       " 'num_std_6mts',\n",
       " 'num_std_12mts',\n",
       " 'num_sub',\n",
       " 'num_sub_6mts',\n",
       " 'num_sub_12mts',\n",
       " 'num_dbt',\n",
       " 'num_dbt_6mts',\n",
       " 'num_dbt_12mts',\n",
       " 'num_lss',\n",
       " 'num_lss_6mts',\n",
       " 'num_lss_12mts',\n",
       " 'recent_level_of_deliq',\n",
       " 'tot_enq',\n",
       " 'CC_enq',\n",
       " 'CC_enq_L6m',\n",
       " 'CC_enq_L12m',\n",
       " 'PL_enq',\n",
       " 'PL_enq_L6m',\n",
       " 'PL_enq_L12m',\n",
       " 'time_since_recent_enq',\n",
       " 'enq_L12m',\n",
       " 'enq_L6m',\n",
       " 'enq_L3m',\n",
       " 'AGE',\n",
       " 'NETMONTHLYINCOME',\n",
       " 'Time_With_Curr_Empr',\n",
       " 'pct_of_active_TLs_ever',\n",
       " 'pct_opened_TLs_L6m_of_L12m',\n",
       " 'pct_currentBal_all_TL',\n",
       " 'CC_Flag',\n",
       " 'PL_Flag',\n",
       " 'pct_PL_enq_L6m_of_L12m',\n",
       " 'pct_CC_enq_L6m_of_L12m',\n",
       " 'pct_PL_enq_L6m_of_ever',\n",
       " 'pct_CC_enq_L6m_of_ever',\n",
       " 'HL_Flag',\n",
       " 'GL_Flag',\n",
       " 'Credit_Score']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "248f059d-7bd8-4c9f-8306-24efa615ccef",
   "metadata": {
    "id": "248f059d-7bd8-4c9f-8306-24efa615ccef"
   },
   "outputs": [],
   "source": [
    "# Now we will check is multicolinearlity exist in our dataset or not.\n",
    "# If exist then we will drop that columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3c031d0-d9ee-496d-be1b-1c095e01672b",
   "metadata": {
    "id": "b3c031d0-d9ee-496d-be1b-1c095e01672b"
   },
   "outputs": [],
   "source": [
    "vif_data = df[numerical_column]\n",
    "total_column = vif_data.shape[1]\n",
    "columns_to_be_kept = []\n",
    "column_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2abcfb8a-750f-4c36-8f59-654ecea047bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2abcfb8a-750f-4c36-8f59-654ecea047bd",
    "outputId": "95dc84f8-5a1a-494a-c0ed-04712856747f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ----- inf\n",
      "0 ----- inf\n",
      "0 ----- 11.320180023967996\n",
      "0 ----- 8.363698035000336\n",
      "0 ----- 6.520647877790928\n",
      "0 ----- 5.149501618212625\n",
      "1 ----- 2.611111040579735\n",
      "2 ----- inf\n",
      "2 ----- 1788.7926256209232\n",
      "2 ----- 8.601028256477228\n",
      "2 ----- 3.8328007921530785\n",
      "3 ----- 6.0996533816467355\n",
      "3 ----- 5.5813520096427585\n",
      "4 ----- 1.9855843530987785\n",
      "5 ----- inf\n",
      "5 ----- 4.809538302819343\n",
      "6 ----- 23.270628983464636\n",
      "6 ----- 30.595522588100053\n",
      "6 ----- 4.384346405965583\n",
      "7 ----- 3.0646584155234238\n",
      "8 ----- 2.898639771299253\n",
      "9 ----- 4.377876915347324\n",
      "10 ----- 2.2078535836958433\n",
      "11 ----- 4.916914200506864\n",
      "12 ----- 5.214702030064725\n",
      "13 ----- 3.3861625024231476\n",
      "14 ----- 7.840583309478997\n",
      "14 ----- 5.255034641721438\n",
      "15 ----- inf\n",
      "15 ----- 7.380634506427232\n",
      "15 ----- 1.4210050015175733\n",
      "16 ----- 8.083255010190323\n",
      "16 ----- 1.6241227524040114\n",
      "17 ----- 7.257811920140003\n",
      "17 ----- 15.59624383268298\n",
      "17 ----- 1.8258570471324314\n",
      "18 ----- 1.5080839450032664\n",
      "19 ----- 2.172088834824578\n",
      "20 ----- 2.623397553527229\n",
      "21 ----- 2.2959970812106176\n",
      "22 ----- 7.360578319196446\n",
      "22 ----- 2.1602387773102563\n",
      "23 ----- 2.8686288267891467\n",
      "24 ----- 6.458218003637277\n",
      "24 ----- 2.8474118865638265\n",
      "25 ----- 4.753198156284083\n",
      "26 ----- 16.22735475594825\n",
      "26 ----- 6.424377256363877\n",
      "26 ----- 8.887080381808687\n",
      "26 ----- 2.3804746142952653\n",
      "27 ----- 8.60951347651454\n",
      "27 ----- 13.06755093547673\n",
      "27 ----- 3.5000400566546555\n",
      "28 ----- 1.9087955874813773\n",
      "29 ----- 17.006562234161628\n",
      "29 ----- 10.730485153719197\n",
      "29 ----- 2.3538497522950266\n",
      "30 ----- 22.104855915136433\n",
      "30 ----- 2.7971639638512906\n",
      "31 ----- 3.424171203217696\n",
      "32 ----- 10.175021454450935\n",
      "32 ----- 6.408710354561301\n",
      "32 ----- 1.001151196262562\n",
      "33 ----- 3.069197305397274\n",
      "34 ----- 2.8091261600643724\n",
      "35 ----- 20.249538381980678\n",
      "35 ----- 15.864576541593774\n",
      "35 ----- 1.8331649740532168\n",
      "36 ----- 1.5680839909542037\n",
      "37 ----- 1.9307572353811682\n",
      "38 ----- 4.331265056645244\n",
      "39 ----- 9.390334396150173\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,total_column):\n",
    "    vif_value = variance_inflation_factor(vif_data,column_index)\n",
    "    print(column_index , '-----', vif_value)\n",
    "\n",
    "    if vif_value <= 6:\n",
    "        columns_to_be_kept.append(numerical_column[i])\n",
    "        column_index += 1\n",
    "\n",
    "    else:\n",
    "        vif_data = vif_data.drop([ numerical_column[i] ],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a9a80e4-a85c-457b-b708-96b72987858b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a9a80e4-a85c-457b-b708-96b72987858b",
    "outputId": "426cab7b-a3de-4317-db92-9c8d4c396c24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pct_tl_open_L6M',\n",
       " 'pct_tl_closed_L6M',\n",
       " 'Tot_TL_closed_L12M',\n",
       " 'pct_tl_closed_L12M',\n",
       " 'Tot_Missed_Pmnt',\n",
       " 'CC_TL',\n",
       " 'Home_TL',\n",
       " 'PL_TL',\n",
       " 'Secured_TL',\n",
       " 'Unsecured_TL',\n",
       " 'Other_TL',\n",
       " 'Age_Oldest_TL',\n",
       " 'Age_Newest_TL',\n",
       " 'time_since_recent_payment',\n",
       " 'max_recent_level_of_deliq',\n",
       " 'num_deliq_6_12mts',\n",
       " 'num_times_60p_dpd',\n",
       " 'num_std_12mts',\n",
       " 'num_sub',\n",
       " 'num_sub_6mts',\n",
       " 'num_sub_12mts',\n",
       " 'num_dbt',\n",
       " 'num_dbt_12mts',\n",
       " 'num_lss',\n",
       " 'num_lss_12mts',\n",
       " 'recent_level_of_deliq',\n",
       " 'CC_enq_L12m',\n",
       " 'PL_enq_L12m',\n",
       " 'time_since_recent_enq',\n",
       " 'enq_L3m',\n",
       " 'NETMONTHLYINCOME',\n",
       " 'Time_With_Curr_Empr',\n",
       " 'pct_currentBal_all_TL',\n",
       " 'CC_Flag',\n",
       " 'PL_Flag',\n",
       " 'pct_PL_enq_L6m_of_ever',\n",
       " 'pct_CC_enq_L6m_of_ever',\n",
       " 'HL_Flag',\n",
       " 'GL_Flag']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_be_kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37a2bf4f-ef09-4bbd-9547-7f16d8406342",
   "metadata": {
    "id": "37a2bf4f-ef09-4bbd-9547-7f16d8406342"
   },
   "outputs": [],
   "source": [
    "columns_to_be_kept_numerical = []\n",
    "\n",
    "for i in columns_to_be_kept:\n",
    "    a = list(df[i])\n",
    "    b = list(df['Approved_Flag'])\n",
    "\n",
    "    group_p1 = [value for value,group in zip(a,b) if group == 'P1']\n",
    "    group_p2 = [value for value,group in zip(a,b) if group == 'P2']\n",
    "    group_p3 = [value for value,group in zip(a,b) if group == 'P3']\n",
    "    group_p4 = [value for value,group in zip(a,b) if group == 'P4']\n",
    "\n",
    "    f_stas,p_value = f_oneway(group_p1,group_p2,group_p3,group_p4)\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        columns_to_be_kept_numerical.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "664186b0-601d-45e9-afb4-5710e97c499a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "664186b0-601d-45e9-afb4-5710e97c499a",
    "outputId": "ed75ea99-c715-4ba5-95a8-acafb294fd22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pct_tl_open_L6M',\n",
       " 'pct_tl_closed_L6M',\n",
       " 'Tot_TL_closed_L12M',\n",
       " 'pct_tl_closed_L12M',\n",
       " 'Tot_Missed_Pmnt',\n",
       " 'CC_TL',\n",
       " 'Home_TL',\n",
       " 'PL_TL',\n",
       " 'Secured_TL',\n",
       " 'Unsecured_TL',\n",
       " 'Other_TL',\n",
       " 'Age_Oldest_TL',\n",
       " 'Age_Newest_TL',\n",
       " 'time_since_recent_payment',\n",
       " 'max_recent_level_of_deliq',\n",
       " 'num_deliq_6_12mts',\n",
       " 'num_times_60p_dpd',\n",
       " 'num_std_12mts',\n",
       " 'num_sub',\n",
       " 'num_sub_6mts',\n",
       " 'num_sub_12mts',\n",
       " 'num_dbt',\n",
       " 'num_dbt_12mts',\n",
       " 'num_lss',\n",
       " 'recent_level_of_deliq',\n",
       " 'CC_enq_L12m',\n",
       " 'PL_enq_L12m',\n",
       " 'time_since_recent_enq',\n",
       " 'enq_L3m',\n",
       " 'NETMONTHLYINCOME',\n",
       " 'Time_With_Curr_Empr',\n",
       " 'CC_Flag',\n",
       " 'PL_Flag',\n",
       " 'pct_PL_enq_L6m_of_ever',\n",
       " 'pct_CC_enq_L6m_of_ever',\n",
       " 'HL_Flag',\n",
       " 'GL_Flag']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_be_kept_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3bc80975-f0a3-4781-a7c0-37f3029721f8",
   "metadata": {
    "id": "3bc80975-f0a3-4781-a7c0-37f3029721f8"
   },
   "outputs": [],
   "source": [
    "features = columns_to_be_kept_numerical + ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2','first_prod_enq2']\n",
    "df = df[features + ['Approved_Flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7f11a0a-f3e4-4569-b0c9-69ab8cbf5931",
   "metadata": {
    "id": "d7f11a0a-f3e4-4569-b0c9-69ab8cbf5931"
   },
   "outputs": [],
   "source": [
    "# Label encoding for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6dc6f09-d787-4980-a359-8c9850cac5d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "c6dc6f09-d787-4980-a359-8c9850cac5d5",
    "outputId": "4ae1f442-1d0a-4bdb-a6c6-34b5f8920889"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        P2\n",
       "1        P2\n",
       "2        P2\n",
       "3        P1\n",
       "4        P3\n",
       "         ..\n",
       "42059    P4\n",
       "42060    P1\n",
       "42061    P3\n",
       "42062    P2\n",
       "42063    P2\n",
       "Name: Approved_Flag, Length: 42064, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Approved_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b05656dd-2843-48ef-b667-a9b3712e67dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b05656dd-2843-48ef-b667-a9b3712e67dd",
    "outputId": "7cdf12ea-76e0-4ca1-8f39-986d84fb0c07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['12TH', 'GRADUATE', 'SSC', 'POST-GRADUATE', 'UNDER GRADUATE',\n",
       "       'OTHERS', 'PROFESSIONAL'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDUCATION'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48d4d616-550b-4c60-9787-325b77632343",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "48d4d616-550b-4c60-9787-325b77632343",
    "outputId": "52c66f2a-f4a2-4d4a-9cd3-23cde96b7271"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Approved_Flag\n",
       "P2    25452\n",
       "P3     6440\n",
       "P4     5264\n",
       "P1     4908\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Approved_Flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f123b41-c231-4769-9c4e-c1b5e0a423ef",
   "metadata": {
    "id": "3f123b41-c231-4769-9c4e-c1b5e0a423ef"
   },
   "outputs": [],
   "source": [
    "# ssc --> 1\n",
    "# 12th and others --> 2\n",
    "# Graduate and undergraduate --> 3\n",
    "# Post graduate --> 4\n",
    "# professional --> 3\n",
    "# others has to be verified by business end user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "970dcd6d-55c2-4d36-9456-78e172f981d2",
   "metadata": {
    "id": "970dcd6d-55c2-4d36-9456-78e172f981d2"
   },
   "outputs": [],
   "source": [
    "df.loc[df['EDUCATION'] == '12TH', 'EDUCATION'] = 2\n",
    "df.loc[df['EDUCATION'] == 'GRADUATE', 'EDUCATION'] = 3\n",
    "df.loc[df['EDUCATION'] == 'SSC', 'EDUCATION'] = 1\n",
    "df.loc[df['EDUCATION'] == 'POST-GRADUATE', 'EDUCATION'] = 4\n",
    "df.loc[df['EDUCATION'] == 'UNDER GRADUATE', 'EDUCATION'] = 3\n",
    "df.loc[df['EDUCATION'] == 'OTHERS', 'EDUCATION'] = 1\n",
    "df.loc[df['EDUCATION'] == 'PROFESSIONAL', 'EDUCATION'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7925b17b-67d2-4a1b-aca3-080c14e8e7bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "7925b17b-67d2-4a1b-aca3-080c14e8e7bb",
    "outputId": "684351f2-bf50-4bd6-dc66-4b3983fa71aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Approved_Flag\n",
       "P2    25452\n",
       "P3     6440\n",
       "P4     5264\n",
       "P1     4908\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Approved_Flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f3de6116-0e1b-4264-917a-c5f590d0e5f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "f3de6116-0e1b-4264-917a-c5f590d0e5f7",
    "outputId": "d0d9c09f-78ad-461c-a12c-0b72458fcff6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EDUCATION\n",
       "3    18931\n",
       "2    11703\n",
       "1     9532\n",
       "4     1898\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDUCATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f1f129f3-8441-4817-9b26-83959a9af7f9",
   "metadata": {
    "id": "f1f129f3-8441-4817-9b26-83959a9af7f9"
   },
   "outputs": [],
   "source": [
    "df['EDUCATION'] = df['EDUCATION'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5a0d1ddd-9847-439a-8c7c-61472d05dd62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a0d1ddd-9847-439a-8c7c-61472d05dd62",
    "outputId": "82c4b662-e44a-467c-fa7d-e048d95d4cb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 42064 entries, 0 to 42063\n",
      "Series name: EDUCATION\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "42064 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 328.8 KB\n"
     ]
    }
   ],
   "source": [
    "df['EDUCATION'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81e75c03-ed73-4d14-ace0-25fb4bfd8a89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "81e75c03-ed73-4d14-ace0-25fb4bfd8a89",
    "outputId": "69d234d4-25b9-4398-befe-ef4291139d76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        P2\n",
       "1        P2\n",
       "2        P2\n",
       "3        P1\n",
       "4        P3\n",
       "         ..\n",
       "42059    P4\n",
       "42060    P1\n",
       "42061    P3\n",
       "42062    P2\n",
       "42063    P2\n",
       "Name: Approved_Flag, Length: 42064, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Approved_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c240b7b0-4534-45df-b253-a912dd9ce423",
   "metadata": {
    "id": "c240b7b0-4534-45df-b253-a912dd9ce423"
   },
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df,columns=['MARITALSTATUS', 'GENDER', 'last_prod_enq2','first_prod_enq2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff30a1c9-29a9-455e-836e-078dc3bfc47d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff30a1c9-29a9-455e-836e-078dc3bfc47d",
    "outputId": "30c0e97f-8d5d-485a-e73d-bb8a468ef51e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42064 entries, 0 to 42063\n",
      "Data columns (total 55 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   pct_tl_open_L6M               42064 non-null  float64\n",
      " 1   pct_tl_closed_L6M             42064 non-null  float64\n",
      " 2   Tot_TL_closed_L12M            42064 non-null  int64  \n",
      " 3   pct_tl_closed_L12M            42064 non-null  float64\n",
      " 4   Tot_Missed_Pmnt               42064 non-null  int64  \n",
      " 5   CC_TL                         42064 non-null  int64  \n",
      " 6   Home_TL                       42064 non-null  int64  \n",
      " 7   PL_TL                         42064 non-null  int64  \n",
      " 8   Secured_TL                    42064 non-null  int64  \n",
      " 9   Unsecured_TL                  42064 non-null  int64  \n",
      " 10  Other_TL                      42064 non-null  int64  \n",
      " 11  Age_Oldest_TL                 42064 non-null  int64  \n",
      " 12  Age_Newest_TL                 42064 non-null  int64  \n",
      " 13  time_since_recent_payment     42064 non-null  int64  \n",
      " 14  max_recent_level_of_deliq     42064 non-null  int64  \n",
      " 15  num_deliq_6_12mts             42064 non-null  int64  \n",
      " 16  num_times_60p_dpd             42064 non-null  int64  \n",
      " 17  num_std_12mts                 42064 non-null  int64  \n",
      " 18  num_sub                       42064 non-null  int64  \n",
      " 19  num_sub_6mts                  42064 non-null  int64  \n",
      " 20  num_sub_12mts                 42064 non-null  int64  \n",
      " 21  num_dbt                       42064 non-null  int64  \n",
      " 22  num_dbt_12mts                 42064 non-null  int64  \n",
      " 23  num_lss                       42064 non-null  int64  \n",
      " 24  recent_level_of_deliq         42064 non-null  int64  \n",
      " 25  CC_enq_L12m                   42064 non-null  int64  \n",
      " 26  PL_enq_L12m                   42064 non-null  int64  \n",
      " 27  time_since_recent_enq         42064 non-null  int64  \n",
      " 28  enq_L3m                       42064 non-null  int64  \n",
      " 29  NETMONTHLYINCOME              42064 non-null  int64  \n",
      " 30  Time_With_Curr_Empr           42064 non-null  int64  \n",
      " 31  CC_Flag                       42064 non-null  int64  \n",
      " 32  PL_Flag                       42064 non-null  int64  \n",
      " 33  pct_PL_enq_L6m_of_ever        42064 non-null  float64\n",
      " 34  pct_CC_enq_L6m_of_ever        42064 non-null  float64\n",
      " 35  HL_Flag                       42064 non-null  int64  \n",
      " 36  GL_Flag                       42064 non-null  int64  \n",
      " 37  EDUCATION                     42064 non-null  int64  \n",
      " 38  Approved_Flag                 42064 non-null  object \n",
      " 39  MARITALSTATUS_Married         42064 non-null  bool   \n",
      " 40  MARITALSTATUS_Single          42064 non-null  bool   \n",
      " 41  GENDER_F                      42064 non-null  bool   \n",
      " 42  GENDER_M                      42064 non-null  bool   \n",
      " 43  last_prod_enq2_AL             42064 non-null  bool   \n",
      " 44  last_prod_enq2_CC             42064 non-null  bool   \n",
      " 45  last_prod_enq2_ConsumerLoan   42064 non-null  bool   \n",
      " 46  last_prod_enq2_HL             42064 non-null  bool   \n",
      " 47  last_prod_enq2_PL             42064 non-null  bool   \n",
      " 48  last_prod_enq2_others         42064 non-null  bool   \n",
      " 49  first_prod_enq2_AL            42064 non-null  bool   \n",
      " 50  first_prod_enq2_CC            42064 non-null  bool   \n",
      " 51  first_prod_enq2_ConsumerLoan  42064 non-null  bool   \n",
      " 52  first_prod_enq2_HL            42064 non-null  bool   \n",
      " 53  first_prod_enq2_PL            42064 non-null  bool   \n",
      " 54  first_prod_enq2_others        42064 non-null  bool   \n",
      "dtypes: bool(16), float64(5), int64(33), object(1)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5fe3c2af-d2ef-4446-ab0f-d5e795450664",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5fe3c2af-d2ef-4446-ab0f-d5e795450664",
    "outputId": "eb0dbbaf-895f-472d-b9f6-407ec66fba5f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pct_tl_open_L6M</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.179032</td>\n",
       "      <td>0.278043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_tl_closed_L6M</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.097783</td>\n",
       "      <td>0.210957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tot_TL_closed_L12M</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.825504</td>\n",
       "      <td>1.537208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_tl_closed_L12M</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.160365</td>\n",
       "      <td>0.258831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tot_Missed_Pmnt</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.525746</td>\n",
       "      <td>1.106442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_TL</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.145921</td>\n",
       "      <td>0.549314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Home_TL</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.076241</td>\n",
       "      <td>0.358582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL_TL</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.916368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Secured_TL</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>2.921334</td>\n",
       "      <td>6.379764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unsecured_TL</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>2.341646</td>\n",
       "      <td>3.405397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other_TL</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>1.116489</td>\n",
       "      <td>2.486801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_Oldest_TL</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>46.498074</td>\n",
       "      <td>42.109230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>65.000</td>\n",
       "      <td>385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_Newest_TL</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>13.970046</td>\n",
       "      <td>18.835191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.000</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_since_recent_payment</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>218.601607</td>\n",
       "      <td>422.282417</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>146.000</td>\n",
       "      <td>6065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_recent_level_of_deliq</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>14.314758</td>\n",
       "      <td>54.056303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.000</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_deliq_6_12mts</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.336963</td>\n",
       "      <td>1.097356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_times_60p_dpd</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.438879</td>\n",
       "      <td>2.148400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_std_12mts</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>3.279978</td>\n",
       "      <td>7.566312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sub</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.063831</td>\n",
       "      <td>0.799989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sub_6mts</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.081704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sub_12mts</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.009224</td>\n",
       "      <td>0.220786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_dbt</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.024510</td>\n",
       "      <td>0.621890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_dbt_12mts</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.184461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_lss</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.016713</td>\n",
       "      <td>0.573762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recent_level_of_deliq</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>11.803918</td>\n",
       "      <td>46.422091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_enq_L12m</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.268924</td>\n",
       "      <td>1.019459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL_enq_L12m</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.779194</td>\n",
       "      <td>1.802092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_since_recent_enq</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>264.854507</td>\n",
       "      <td>466.585002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>302.000</td>\n",
       "      <td>4768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enq_L3m</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>1.230458</td>\n",
       "      <td>2.069461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NETMONTHLYINCOME</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>26929.896800</td>\n",
       "      <td>20842.999867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>31000.000</td>\n",
       "      <td>2500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time_With_Curr_Empr</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>110.345783</td>\n",
       "      <td>75.629967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>131.000</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_Flag</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.102962</td>\n",
       "      <td>0.303913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL_Flag</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.193063</td>\n",
       "      <td>0.394707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_PL_enq_L6m_of_ever</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.195497</td>\n",
       "      <td>0.367414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_CC_enq_L6m_of_ever</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.064186</td>\n",
       "      <td>0.225989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HL_Flag</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.252235</td>\n",
       "      <td>0.434300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL_Flag</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>0.056580</td>\n",
       "      <td>0.231042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION</th>\n",
       "      <td>42064.0</td>\n",
       "      <td>2.313689</td>\n",
       "      <td>0.871070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             count          mean           std  min      25%  \\\n",
       "pct_tl_open_L6M            42064.0      0.179032      0.278043  0.0      0.0   \n",
       "pct_tl_closed_L6M          42064.0      0.097783      0.210957  0.0      0.0   \n",
       "Tot_TL_closed_L12M         42064.0      0.825504      1.537208  0.0      0.0   \n",
       "pct_tl_closed_L12M         42064.0      0.160365      0.258831  0.0      0.0   \n",
       "Tot_Missed_Pmnt            42064.0      0.525746      1.106442  0.0      0.0   \n",
       "CC_TL                      42064.0      0.145921      0.549314  0.0      0.0   \n",
       "Home_TL                    42064.0      0.076241      0.358582  0.0      0.0   \n",
       "PL_TL                      42064.0      0.328000      0.916368  0.0      0.0   \n",
       "Secured_TL                 42064.0      2.921334      6.379764  0.0      0.0   \n",
       "Unsecured_TL               42064.0      2.341646      3.405397  0.0      0.0   \n",
       "Other_TL                   42064.0      1.116489      2.486801  0.0      0.0   \n",
       "Age_Oldest_TL              42064.0     46.498074     42.109230  0.0     14.0   \n",
       "Age_Newest_TL              42064.0     13.970046     18.835191  0.0      4.0   \n",
       "time_since_recent_payment  42064.0    218.601607    422.282417  2.0     51.0   \n",
       "max_recent_level_of_deliq  42064.0     14.314758     54.056303  0.0      0.0   \n",
       "num_deliq_6_12mts          42064.0      0.336963      1.097356  0.0      0.0   \n",
       "num_times_60p_dpd          42064.0      0.438879      2.148400  0.0      0.0   \n",
       "num_std_12mts              42064.0      3.279978      7.566312  0.0      0.0   \n",
       "num_sub                    42064.0      0.063831      0.799989  0.0      0.0   \n",
       "num_sub_6mts               42064.0      0.002211      0.081704  0.0      0.0   \n",
       "num_sub_12mts              42064.0      0.009224      0.220786  0.0      0.0   \n",
       "num_dbt                    42064.0      0.024510      0.621890  0.0      0.0   \n",
       "num_dbt_12mts              42064.0      0.004279      0.184461  0.0      0.0   \n",
       "num_lss                    42064.0      0.016713      0.573762  0.0      0.0   \n",
       "recent_level_of_deliq      42064.0     11.803918     46.422091  0.0      0.0   \n",
       "CC_enq_L12m                42064.0      0.268924      1.019459  0.0      0.0   \n",
       "PL_enq_L12m                42064.0      0.779194      1.802092  0.0      0.0   \n",
       "time_since_recent_enq      42064.0    264.854507    466.585002  0.0      9.0   \n",
       "enq_L3m                    42064.0      1.230458      2.069461  0.0      0.0   \n",
       "NETMONTHLYINCOME           42064.0  26929.896800  20842.999867  0.0  18000.0   \n",
       "Time_With_Curr_Empr        42064.0    110.345783     75.629967  0.0     61.0   \n",
       "CC_Flag                    42064.0      0.102962      0.303913  0.0      0.0   \n",
       "PL_Flag                    42064.0      0.193063      0.394707  0.0      0.0   \n",
       "pct_PL_enq_L6m_of_ever     42064.0      0.195497      0.367414  0.0      0.0   \n",
       "pct_CC_enq_L6m_of_ever     42064.0      0.064186      0.225989  0.0      0.0   \n",
       "HL_Flag                    42064.0      0.252235      0.434300  0.0      0.0   \n",
       "GL_Flag                    42064.0      0.056580      0.231042  0.0      0.0   \n",
       "EDUCATION                  42064.0      2.313689      0.871070  1.0      2.0   \n",
       "\n",
       "                               50%        75%        max  \n",
       "pct_tl_open_L6M                0.0      0.333        1.0  \n",
       "pct_tl_closed_L6M              0.0      0.100        1.0  \n",
       "Tot_TL_closed_L12M             0.0      1.000       33.0  \n",
       "pct_tl_closed_L12M             0.0      0.250        1.0  \n",
       "Tot_Missed_Pmnt                0.0      1.000       34.0  \n",
       "CC_TL                          0.0      0.000       27.0  \n",
       "Home_TL                        0.0      0.000       10.0  \n",
       "PL_TL                          0.0      0.000       29.0  \n",
       "Secured_TL                     1.0      3.000      235.0  \n",
       "Unsecured_TL                   1.0      3.000       55.0  \n",
       "Other_TL                       0.0      1.000       80.0  \n",
       "Age_Oldest_TL                 34.0     65.000      385.0  \n",
       "Age_Newest_TL                  7.0     16.000      359.0  \n",
       "time_since_recent_payment     71.0    146.000     6065.0  \n",
       "max_recent_level_of_deliq      0.0     15.000      900.0  \n",
       "num_deliq_6_12mts              0.0      0.000       20.0  \n",
       "num_times_60p_dpd              0.0      0.000       52.0  \n",
       "num_std_12mts                  0.0      3.000      122.0  \n",
       "num_sub                        0.0      0.000       41.0  \n",
       "num_sub_6mts                   0.0      0.000        5.0  \n",
       "num_sub_12mts                  0.0      0.000       12.0  \n",
       "num_dbt                        0.0      0.000       35.0  \n",
       "num_dbt_12mts                  0.0      0.000       12.0  \n",
       "num_lss                        0.0      0.000       72.0  \n",
       "recent_level_of_deliq          0.0     11.000      900.0  \n",
       "CC_enq_L12m                    0.0      0.000       24.0  \n",
       "PL_enq_L12m                    0.0      1.000       44.0  \n",
       "time_since_recent_enq         79.0    302.000     4768.0  \n",
       "enq_L3m                        1.0      2.000       42.0  \n",
       "NETMONTHLYINCOME           24000.0  31000.000  2500000.0  \n",
       "Time_With_Curr_Empr           92.0    131.000     1020.0  \n",
       "CC_Flag                        0.0      0.000        1.0  \n",
       "PL_Flag                        0.0      0.000        1.0  \n",
       "pct_PL_enq_L6m_of_ever         0.0      0.000        1.0  \n",
       "pct_CC_enq_L6m_of_ever         0.0      0.000        1.0  \n",
       "HL_Flag                        0.0      1.000        1.0  \n",
       "GL_Flag                        0.0      0.000        1.0  \n",
       "EDUCATION                      2.0      3.000        4.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "298090e0-c934-411d-8cd8-5d6028725d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pct_tl_open_L6M</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_tl_closed_L6M</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tot_TL_closed_L12M</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_tl_closed_L12M</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tot_Missed_Pmnt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_TL</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Home_TL</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL_TL</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Secured_TL</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unsecured_TL</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other_TL</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_Oldest_TL</th>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>131</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_Newest_TL</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_since_recent_payment</th>\n",
       "      <td>549</td>\n",
       "      <td>47</td>\n",
       "      <td>302</td>\n",
       "      <td>583</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_recent_level_of_deliq</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_deliq_6_12mts</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_times_60p_dpd</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_std_12mts</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sub</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sub_6mts</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sub_12mts</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_dbt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_dbt_12mts</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_lss</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recent_level_of_deliq</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_enq_L12m</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL_enq_L12m</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_since_recent_enq</th>\n",
       "      <td>566</td>\n",
       "      <td>209</td>\n",
       "      <td>587</td>\n",
       "      <td>3951</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enq_L3m</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NETMONTHLYINCOME</th>\n",
       "      <td>51000</td>\n",
       "      <td>19000</td>\n",
       "      <td>18</td>\n",
       "      <td>15000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time_With_Curr_Empr</th>\n",
       "      <td>114</td>\n",
       "      <td>50</td>\n",
       "      <td>191</td>\n",
       "      <td>75</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_Flag</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL_Flag</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_PL_enq_L6m_of_ever</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_CC_enq_L6m_of_ever</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HL_Flag</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL_Flag</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Approved_Flag</th>\n",
       "      <td>P2</td>\n",
       "      <td>P2</td>\n",
       "      <td>P2</td>\n",
       "      <td>P1</td>\n",
       "      <td>P3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARITALSTATUS_Married</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARITALSTATUS_Single</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GENDER_F</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GENDER_M</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_prod_enq2_AL</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_prod_enq2_CC</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_prod_enq2_ConsumerLoan</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_prod_enq2_HL</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_prod_enq2_PL</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_prod_enq2_others</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_prod_enq2_AL</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_prod_enq2_CC</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_prod_enq2_ConsumerLoan</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_prod_enq2_HL</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_prod_enq2_PL</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_prod_enq2_others</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0      1      2      3      4\n",
       "pct_tl_open_L6M                 0.0    0.0  0.125    0.0    0.0\n",
       "pct_tl_closed_L6M               0.0    0.0    0.0    0.0    0.0\n",
       "Tot_TL_closed_L12M                0      0      0      0      1\n",
       "pct_tl_closed_L12M              0.0    0.0    0.0    0.0  0.167\n",
       "Tot_Missed_Pmnt                   0      0      1      0      0\n",
       "CC_TL                             0      0      0      0      0\n",
       "Home_TL                           0      0      0      0      0\n",
       "PL_TL                             4      0      0      0      0\n",
       "Secured_TL                        1      0      2      3      6\n",
       "Unsecured_TL                      4      1      6      0      0\n",
       "Other_TL                          0      0      0      2      0\n",
       "Age_Oldest_TL                    72      7     47    131    150\n",
       "Age_Newest_TL                    18      7      2     32     17\n",
       "time_since_recent_payment       549     47    302    583    245\n",
       "max_recent_level_of_deliq        29      0     25      0    270\n",
       "num_deliq_6_12mts                 0      0      8      0      0\n",
       "num_times_60p_dpd                 0      0      0      0     11\n",
       "num_std_12mts                    11      0     10     16      2\n",
       "num_sub                           0      0      0      0      3\n",
       "num_sub_6mts                      0      0      0      0      0\n",
       "num_sub_12mts                     0      0      0      0      1\n",
       "num_dbt                           0      0      0      0      0\n",
       "num_dbt_12mts                     0      0      0      0      0\n",
       "num_lss                           0      0      0      0      0\n",
       "recent_level_of_deliq            29      0     25      0     26\n",
       "CC_enq_L12m                       0      0      0      0      1\n",
       "PL_enq_L12m                       0      0      0      0      3\n",
       "time_since_recent_enq           566    209    587   3951      7\n",
       "enq_L3m                           0      0      0      0      4\n",
       "NETMONTHLYINCOME              51000  19000     18  15000      0\n",
       "Time_With_Curr_Empr             114     50    191     75    154\n",
       "CC_Flag                           0      0      0      0      0\n",
       "PL_Flag                           1      0      0      0      0\n",
       "pct_PL_enq_L6m_of_ever          0.0    0.0    0.0    0.0  0.429\n",
       "pct_CC_enq_L6m_of_ever          0.0    0.0    0.0    0.0    0.0\n",
       "HL_Flag                           1      0      1      0      1\n",
       "GL_Flag                           0      0      0      0      0\n",
       "EDUCATION                         2      3      1      4      2\n",
       "Approved_Flag                    P2     P2     P2     P1     P3\n",
       "MARITALSTATUS_Married          True  False   True   True   True\n",
       "MARITALSTATUS_Single          False   True  False  False  False\n",
       "GENDER_F                      False   True  False  False  False\n",
       "GENDER_M                       True  False   True   True   True\n",
       "last_prod_enq2_AL             False  False  False   True  False\n",
       "last_prod_enq2_CC             False  False  False  False  False\n",
       "last_prod_enq2_ConsumerLoan   False   True   True  False   True\n",
       "last_prod_enq2_HL             False  False  False  False  False\n",
       "last_prod_enq2_PL              True  False  False  False  False\n",
       "last_prod_enq2_others         False  False  False  False  False\n",
       "first_prod_enq2_AL            False  False  False   True  False\n",
       "first_prod_enq2_CC            False  False  False  False  False\n",
       "first_prod_enq2_ConsumerLoan  False   True  False  False  False\n",
       "first_prod_enq2_HL            False  False  False  False  False\n",
       "first_prod_enq2_PL             True  False  False  False   True\n",
       "first_prod_enq2_others        False  False   True  False  False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25972e19-2af7-4d7c-b9c9-eab77c5955b0",
   "metadata": {
    "id": "25972e19-2af7-4d7c-b9c9-eab77c5955b0"
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a64ce6e-9d83-460e-bc20-07daa0ff3ddb",
   "metadata": {
    "id": "2a64ce6e-9d83-460e-bc20-07daa0ff3ddb"
   },
   "outputs": [],
   "source": [
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded.drop(['Approved_Flag'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b6b22fb-3f3c-4da1-b616-e39927a379e6",
   "metadata": {
    "id": "6b6b22fb-3f3c-4da1-b616-e39927a379e6"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train , y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "67cbb8a8-2e71-4084-8a1b-6991cbba96fa",
   "metadata": {
    "id": "67cbb8a8-2e71-4084-8a1b-6991cbba96fa"
   },
   "outputs": [],
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "100e6030-4ca0-4f8b-b00b-5a2ab851740d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "100e6030-4ca0-4f8b-b00b-5a2ab851740d",
    "outputId": "80633e33-8832-463e-d259-9b5818efd032"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">200</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">bootstrap&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">oob_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_samples&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Random forest\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200,random_state=42)\n",
    "rfc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f45d8601-1d41-486c-ac6c-dad69146ce0c",
   "metadata": {
    "id": "f45d8601-1d41-486c-ac6c-dad69146ce0c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "87c5c3d9-505d-4624-839a-9ddf06287f1f",
   "metadata": {
    "id": "87c5c3d9-505d-4624-839a-9ddf06287f1f"
   },
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ed051d1b-13f0-4a09-bd14-53b0288acb88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ed051d1b-13f0-4a09-bd14-53b0288acb88",
    "outputId": "23cf112d-6602-47d7-8dff-d807f73fa561"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7636990372043266"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2fe438a8-c771-4689-b6c9-902f527802f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fe438a8-c771-4689-b6c9-902f527802f6",
    "outputId": "6988e6b7-1007-4d62-d9a5-3f77bd74348a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.70      0.84      0.76       853\n",
      "          P2       0.93      0.80      0.86      5885\n",
      "          P3       0.21      0.44      0.29       633\n",
      "          P4       0.73      0.72      0.72      1042\n",
      "\n",
      "    accuracy                           0.76      8413\n",
      "   macro avg       0.64      0.70      0.66      8413\n",
      "weighted avg       0.83      0.76      0.79      8413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "OcU1xhbKANr4",
   "metadata": {
    "id": "OcU1xhbKANr4"
   },
   "outputs": [],
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9b6c4bce-be44-4d5e-8a88-93c95d8e2ce9",
   "metadata": {
    "id": "9b6c4bce-be44-4d5e-8a88-93c95d8e2ce9"
   },
   "outputs": [],
   "source": [
    "y_xgb = df_encoded['Approved_Flag']\n",
    "x_xgb = df_encoded.drop(['Approved_Flag'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ddd044cb-d96a-4d1d-a5fc-ebed9dc7ff02",
   "metadata": {
    "id": "ddd044cb-d96a-4d1d-a5fc-ebed9dc7ff02"
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0eb8135-9f99-425b-8bbb-0c3350e3609e",
   "metadata": {
    "id": "b0eb8135-9f99-425b-8bbb-0c3350e3609e"
   },
   "outputs": [],
   "source": [
    "x_train_xgb,x_test_xgb,y_train_xgb,y_test_xgb = train_test_split(x_xgb,y_encoded,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "56ce4ac3-c0f8-4927-be15-278634ba3a54",
   "metadata": {
    "id": "56ce4ac3-c0f8-4927-be15-278634ba3a54"
   },
   "outputs": [],
   "source": [
    "xgb_classifier = xgboost.XGBClassifier(objective='multi:soft_max',num_class=4,tree_method='hist',device='cuda' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "60816dd9-bbf6-4c66-ab78-afad82a70eb1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "60816dd9-bbf6-4c66-ab78-afad82a70eb1",
    "outputId": "b5a55f48-d843-412b-8cab-4c31f3e70a8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_class=4, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;multi:softprob&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;cuda&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;hist&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_class&nbsp;</td>\n",
       "            <td class=\"value\">4</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device='cuda', early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_class=4, ...)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier.fit(x_train_xgb,y_train_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e5513319-5f29-4667-a023-7f79bddd3a41",
   "metadata": {
    "id": "e5513319-5f29-4667-a023-7f79bddd3a41"
   },
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c70308a6-7a65-4712-ad9b-125c5fb70361",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c70308a6-7a65-4712-ad9b-125c5fb70361",
    "outputId": "906d5bd9-b24a-4b54-a3e4-8dfebfd1ed8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7748722215618685"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_xgb,y_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e80f627-fdd9-4937-b32d-d74ebc1d92a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e80f627-fdd9-4937-b32d-d74ebc1d92a2",
    "outputId": "6b95fdd2-ad58-4ff3-ce3b-5ae6e774d104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78       933\n",
      "           1       0.91      0.82      0.87      5601\n",
      "           2       0.30      0.46      0.36       854\n",
      "           3       0.74      0.74      0.74      1025\n",
      "\n",
      "    accuracy                           0.77      8413\n",
      "   macro avg       0.67      0.71      0.69      8413\n",
      "weighted avg       0.81      0.77      0.79      8413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_xgb,y_test_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92341fb-7625-41db-ba70-a9a531f65abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1e15642e-0aad-4eed-809b-c9628b106947",
   "metadata": {
    "id": "1e15642e-0aad-4eed-809b-c9628b106947"
   },
   "outputs": [],
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ab741b4f-2c86-460a-9cba-30aceb6bb979",
   "metadata": {
    "id": "ab741b4f-2c86-460a-9cba-30aceb6bb979"
   },
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(max_depth=20,min_samples_split=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "n3Z1p-7t_uRf",
   "metadata": {
    "id": "n3Z1p-7t_uRf"
   },
   "outputs": [],
   "source": [
    "dt_classifier.fit(x_train,y_train)\n",
    "y_pred_dt = dt_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "Mj9vGlsJAuTV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mj9vGlsJAuTV",
    "outputId": "2325f1eb-23d9-4fc2-acc2-b648d683791d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7096160703672887"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_dt,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "QJkOdG38A1DR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QJkOdG38A1DR",
    "outputId": "7d40609e-0fb9-4c4b-e2c9-d8043c0dd4c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.73      0.72      0.72      1028\n",
      "          P2       0.82      0.81      0.82      5135\n",
      "          P3       0.33      0.34      0.34      1267\n",
      "          P4       0.62      0.65      0.64       983\n",
      "\n",
      "    accuracy                           0.71      8413\n",
      "   macro avg       0.63      0.63      0.63      8413\n",
      "weighted avg       0.71      0.71      0.71      8413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_dt,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "LIMkR8c_A5tp",
   "metadata": {
    "id": "LIMkR8c_A5tp"
   },
   "outputs": [],
   "source": [
    "# Xgboost give highest accuracy among 3, so we will choose xgboost to fine tune further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "PsV8N-XwhS6V",
   "metadata": {
    "id": "PsV8N-XwhS6V"
   },
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "# for tuning we will use Random search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "RMoveo8ihZd5",
   "metadata": {
    "id": "RMoveo8ihZd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurcay on test :  0.7801022227505052\n",
      "Accurcay on train :  0.8149534932097114\n",
      "Classification report on train : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84      3734\n",
      "           1       0.94      0.84      0.89     22600\n",
      "           2       0.37      0.57      0.45      3254\n",
      "           3       0.77      0.81      0.79      4063\n",
      "\n",
      "    accuracy                           0.81     33651\n",
      "   macro avg       0.72      0.77      0.74     33651\n",
      "weighted avg       0.85      0.81      0.83     33651\n",
      "\n",
      "Classification report on test : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       939\n",
      "           1       0.92      0.83      0.87      5616\n",
      "           2       0.29      0.46      0.36       834\n",
      "           3       0.73      0.73      0.73      1024\n",
      "\n",
      "    accuracy                           0.78      8413\n",
      "   macro avg       0.68      0.72      0.69      8413\n",
      "weighted avg       0.82      0.78      0.80      8413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In video tutorial after doing hyperparameter tuning they get this result of accuracy of 78%\n",
    "# Parameter used by tutor for hyperparameter tuning\n",
    "# param_grid = {\n",
    "#     'colsample_bytree':[0.1,0.3,0.5,0.7,0.9],\n",
    "#     'learning_rate':[0.001,0.01,0.1,1],\n",
    "#     'max_depth':[3,5,8,10],\n",
    "#     'alpha': [0, 1, 5],\n",
    "#     'n_estimators':[10,50,100]\n",
    "# }\n",
    "# Best parameter:  {'alpha': 0, 'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
    "# Best accuracy:  0.7789070161362218\n",
    "# I tried this parameter to tune on colab notebook and this is the best parameter and score\n",
    "y_xgb = df_encoded['Approved_Flag']\n",
    "x_xgb = df_encoded.drop(['Approved_Flag'],axis=1)\n",
    "label_encoder = LabelEncoder()\n",
    "x_train_xgb,x_test_xgb,y_train_xgb,y_test_xgb = train_test_split(x_xgb,y_encoded,random_state=42,test_size=0.2)\n",
    "y_encoded = label_encoder.fit_transform(y_xgb)\n",
    "xgb_classifier_cv = xgboost.XGBClassifier(objective='multi:soft_max',num_class=4,\n",
    "                                          alpha=10,colsample_bytree=0.9,learning_rate=1\n",
    "                                          ,max_depth=3,n_estimators=100,tree_method='hist',\n",
    "                                          device='cuda' )\n",
    "xgb_classifier_cv.fit(x_train_xgb,y_train_xgb)\n",
    "print(\"Accurcay on test : \",accuracy_score(xgb_classifier_cv.predict(x_test_xgb),y_test_xgb))\n",
    "print(\"Accurcay on train : \",accuracy_score(xgb_classifier_cv.predict(x_train_xgb),y_train_xgb))\n",
    "print(\"Classification report on train : \\n\",classification_report(xgb_classifier_cv.predict(x_train_xgb),y_train_xgb))\n",
    "print(\"Classification report on test : \\n\",classification_report(xgb_classifier_cv.predict(x_test_xgb),y_test_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "131c4fec-01ae-4a9b-9f23-84dc2e50ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now my goal is to maixmize the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "197885fc-0a26-4f9d-a8a4-0cd78c1da3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lightgbm.LGBMClassifier(\n",
    "    device='gpu',\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "883cefe5-3c12-48a4-a928-1d9e9c55ca35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 3028\n",
      "[LightGBM] [Info] Number of data points in the train set: 33651, number of used features: 54\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 6GB Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.51 MB) transferred to GPU in 0.005942 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -2.156606\n",
      "[LightGBM] [Info] Start training from score -0.500165\n",
      "[LightGBM] [Info] Start training from score -1.883865\n",
      "[LightGBM] [Info] Start training from score -2.072659\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(device=&#x27;gpu&#x27;, learning_rate=0.05, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('boosting_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">boosting_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gbdt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves&nbsp;</td>\n",
       "            <td class=\"value\">31</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.05</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">200</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_for_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_for_bin&nbsp;</td>\n",
       "            <td class=\"value\">200000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_split_gain',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_split_gain&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples&nbsp;</td>\n",
       "            <td class=\"value\">20</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_freq',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_freq&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;split&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gpu&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LGBMClassifier(device='gpu', learning_rate=0.05, n_estimators=200)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e69d2d73-8bc2-4def-8a08-a1f088e6a26b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7795079044336146"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(lgbm.predict(x_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2b453cdc-7086-4f4b-8ac7-be3ddda6cb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.78      0.83      0.80       950\n",
      "          P2       0.92      0.82      0.87      5619\n",
      "          P3       0.28      0.46      0.35       813\n",
      "          P4       0.74      0.74      0.74      1031\n",
      "\n",
      "    accuracy                           0.78      8413\n",
      "   macro avg       0.68      0.71      0.69      8413\n",
      "weighted avg       0.82      0.78      0.80      8413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(lgbm.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7b129ce0-21b7-475a-bf22-89b5e4b1fa3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurcay on test :  0.7795079044336146\n",
      "Accurcay on train :  0.8480877239903718\n",
      "Classification report on train : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.86      0.89      0.88      3784\n",
      "          P2       0.95      0.86      0.90     22489\n",
      "          P3       0.44      0.68      0.54      3300\n",
      "          P4       0.83      0.86      0.85      4078\n",
      "\n",
      "    accuracy                           0.85     33651\n",
      "   macro avg       0.77      0.82      0.79     33651\n",
      "weighted avg       0.88      0.85      0.86     33651\n",
      "\n",
      "Classification report on test : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.78      0.83      0.80       950\n",
      "          P2       0.92      0.82      0.87      5619\n",
      "          P3       0.28      0.46      0.35       813\n",
      "          P4       0.74      0.74      0.74      1031\n",
      "\n",
      "    accuracy                           0.78      8413\n",
      "   macro avg       0.68      0.71      0.69      8413\n",
      "weighted avg       0.82      0.78      0.80      8413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accurcay on test : \",accuracy_score(lgbm.predict(x_test),y_test))\n",
    "print(\"Accurcay on train : \",accuracy_score(lgbm.predict(x_train),y_train))\n",
    "print(\"Classification report on train : \\n\",classification_report(lgbm.predict(x_train),y_train))\n",
    "print(\"Classification report on test : \\n\",classification_report(lgbm.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c0d1c-d68d-4aa7-951c-b3462ead4987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c1617d7d-1f11-4e0b-9526-15c7939a8721",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'num_leaves': [31, 63, 127],\n",
    "    'max_depth': [-1, 7, 12],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [200, 500, 1000],\n",
    "    'subsample': [0.7, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.9, 1.0],\n",
    "    'reg_lambda': [0, 1, 5],\n",
    "    'reg_alpha': [0, 1, 5]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba6feaec-5561-4886-946c-6a2aa41843c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2823\n",
      "[LightGBM] [Info] Number of data points in the train set: 22434, number of used features: 53\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 6GB Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.34 MB) transferred to GPU in 0.002843 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -2.156606\n",
      "[LightGBM] [Info] Start training from score -0.500214\n",
      "[LightGBM] [Info] Start training from score -1.883865\n",
      "[LightGBM] [Info] Start training from score -2.072423\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=-1, n_estimators=500, num_leaves=63, reg_alpha=5, reg_lambda=1, subsample=1.0; total time=  59.4s\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2807\n",
      "[LightGBM] [Info] Number of data points in the train set: 22434, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 6GB Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.34 MB) transferred to GPU in 0.002758 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -2.156606\n",
      "[LightGBM] [Info] Start training from score -0.500140\n",
      "[LightGBM] [Info] Start training from score -1.883865\n",
      "[LightGBM] [Info] Start training from score -2.072778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = RandomizedSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=40,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    # n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c4c17-bf7d-4cdc-9a09-aba48f2d15df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy :',accuracy_score(lgbm.predict(x_test),y_test))\n",
    "print('Train accuracy :',accuracy_score(lgbm.predict(x_train),y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f24ded15-b60f-459c-b03b-e34c67d0ba6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 3028\n",
      "[LightGBM] [Info] Number of data points in the train set: 33651, number of used features: 54\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 6GB Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.51 MB) transferred to GPU in 0.003962 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -2.156606\n",
      "[LightGBM] [Info] Start training from score -0.500165\n",
      "[LightGBM] [Info] Start training from score -1.883865\n",
      "[LightGBM] [Info] Start training from score -2.072659\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(colsample_bytree=0.7, device=&#x27;gpu&#x27;, learning_rate=0.01,\n",
       "               n_estimators=1000, reg_alpha=0, reg_lambda=5, subsample=0.9)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('boosting_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">boosting_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gbdt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves&nbsp;</td>\n",
       "            <td class=\"value\">31</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.01</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_for_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_for_bin&nbsp;</td>\n",
       "            <td class=\"value\">200000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_split_gain',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_split_gain&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples&nbsp;</td>\n",
       "            <td class=\"value\">20</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_freq',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_freq&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;split&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gpu&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.7, device='gpu', learning_rate=0.01,\n",
       "               n_estimators=1000, reg_alpha=0, reg_lambda=5, subsample=0.9)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = lightgbm.LGBMClassifier(\n",
    "    device='gpu',\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=31,\n",
    "    max_depth= -1,\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=1000,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.7,\n",
    "    reg_lambda=5,\n",
    "    reg_alpha=0\n",
    "    \n",
    ")\n",
    "lgbm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "21f42f5a-b9a6-4d7d-a0ef-5fc70be88359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurcay on test :  0.7815285867110424\n",
      "Accurcay on train :  0.8332887581349737\n",
      "Classification report on train : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.85      0.88      0.86      3769\n",
      "          P2       0.94      0.85      0.90     22566\n",
      "          P3       0.39      0.63      0.49      3182\n",
      "          P4       0.81      0.83      0.82      4134\n",
      "\n",
      "    accuracy                           0.83     33651\n",
      "   macro avg       0.75      0.80      0.77     33651\n",
      "weighted avg       0.87      0.83      0.85     33651\n",
      "\n",
      "Classification report on test : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.77      0.83      0.80       941\n",
      "          P2       0.92      0.82      0.87      5622\n",
      "          P3       0.29      0.47      0.36       806\n",
      "          P4       0.75      0.74      0.75      1044\n",
      "\n",
      "    accuracy                           0.78      8413\n",
      "   macro avg       0.68      0.72      0.69      8413\n",
      "weighted avg       0.82      0.78      0.80      8413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accurcay on test : \",accuracy_score(lgbm.predict(x_test),y_test))\n",
    "print(\"Accurcay on train : \",accuracy_score(lgbm.predict(x_train),y_train))\n",
    "print(\"Classification report on train : \\n\",classification_report(lgbm.predict(x_train),y_train))\n",
    "print(\"Classification report on test : \\n\",classification_report(lgbm.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a6125-2427-4665-a82b-ed682a607d30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_distributions=param_dist,\n",
    "    # n_iter=30,               # ✅ only 30 smart tries\n",
    "    scoring='accuracy',      # change to f1_macro if imbalanced\n",
    "    cv=3,                    # 3-fold CV is enough\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    # n_jobs=-1               # use all CPU cores\n",
    ")\n",
    "\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Best result\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57116448-517b-4147-bdba-c77b3b7c13fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tried on colab notebook\n",
    "# Best Parameters: {'subsample': 0.9, 'reg_lambda': 5, 'reg_alpha': 0, 'num_leaves': 127, 'n_estimators': 1000, 'max_depth': 7, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
    "# Best Score: 0.7787287153427833\n",
    "# Best Parameters: {'subsample': 0.7, 'reg_lambda': 1, 'reg_alpha': 0, 'num_leaves': 31, 'n_estimators': 200, 'max_depth': -1, 'learning_rate': 0.05, 'colsample_bytree': 0.9}\n",
    "# Best Score: 0.7797985201034144\n",
    "# ✅ Best LGBM Parameters: {'subsample': 0.8, 'reg_lambda': 5, 'reg_alpha': 1, 'num_leaves': 20, 'n_estimators': 700, 'min_child_samples': 20, 'max_depth': 8, 'learning_rate': 0.02, 'colsample_bytree': 0.7}\n",
    "\n",
    "# ✅ LGBM Train Accuracy: 0.824076550473983\n",
    "# ✅ LGBM Test Accuracy: 0.782241768691311\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c903db46-57ae-4820-9bd5-322f9eb1cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "91ef8691-df42-40d0-b7d8-02e10108673f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=400, reg_alpha=3, reg_lambda=3, subsample=1.0; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=400, reg_alpha=3, reg_lambda=3, subsample=1.0; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=400, reg_alpha=3, reg_lambda=3, subsample=1.0; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=400, reg_alpha=3, reg_lambda=3, subsample=1.0; total time=  13.2s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=400, reg_alpha=3, reg_lambda=3, subsample=1.0; total time=  13.4s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=3, reg_lambda=5, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=3, reg_lambda=5, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=3, reg_lambda=5, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=3, reg_lambda=5, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=3, reg_lambda=5, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.8; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=3, reg_lambda=5, subsample=0.8; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=3, reg_lambda=5, subsample=0.8; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=3, reg_lambda=5, subsample=0.8; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=3, reg_lambda=5, subsample=0.8; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=3, reg_lambda=5, subsample=0.8; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=200, reg_alpha=3, reg_lambda=3, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=200, reg_alpha=3, reg_lambda=3, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=200, reg_alpha=3, reg_lambda=3, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=200, reg_alpha=3, reg_lambda=3, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=200, reg_alpha=3, reg_lambda=3, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=0.7; total time=  12.7s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=0.7; total time=  12.9s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=0.7; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=0.7; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=0.7; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=1.0; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=1.0; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=1.0; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=1.0; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=1.0; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=3, subsample=0.8; total time=  18.0s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=3, subsample=0.8; total time=  17.9s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=3, subsample=0.8; total time=  19.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=3, subsample=0.8; total time=  18.4s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=3, subsample=0.8; total time=  19.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=400, reg_alpha=3, reg_lambda=1, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=400, reg_alpha=3, reg_lambda=1, subsample=0.8; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=400, reg_alpha=3, reg_lambda=1, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=400, reg_alpha=3, reg_lambda=1, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=400, reg_alpha=3, reg_lambda=1, subsample=0.8; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=3, reg_lambda=3, subsample=0.7; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=3, reg_lambda=3, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=3, reg_lambda=3, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=3, reg_lambda=3, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=3, reg_lambda=3, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=1, subsample=0.7; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=1, subsample=0.7; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=1, subsample=0.7; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=1, subsample=0.7; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=1, subsample=0.7; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=3, subsample=1.0; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=3, subsample=1.0; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=3, subsample=1.0; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=3, subsample=1.0; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=3, subsample=1.0; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=3, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=5, subsample=0.7; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=5, subsample=0.7; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=5, subsample=0.7; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=5, subsample=0.7; total time=  12.9s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=5, subsample=0.7; total time=  12.9s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=600, reg_alpha=3, reg_lambda=5, subsample=1.0; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=600, reg_alpha=3, reg_lambda=5, subsample=1.0; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=600, reg_alpha=3, reg_lambda=5, subsample=1.0; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=600, reg_alpha=3, reg_lambda=5, subsample=1.0; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=5, n_estimators=600, reg_alpha=3, reg_lambda=5, subsample=1.0; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=1.0; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=1.0; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=1.0; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=1.0; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=1.0; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=600, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=9, min_child_weight=10, n_estimators=200, reg_alpha=1, reg_lambda=3, subsample=1.0; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=9, min_child_weight=10, n_estimators=200, reg_alpha=1, reg_lambda=3, subsample=1.0; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=9, min_child_weight=10, n_estimators=200, reg_alpha=1, reg_lambda=3, subsample=1.0; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=9, min_child_weight=10, n_estimators=200, reg_alpha=1, reg_lambda=3, subsample=1.0; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=9, min_child_weight=10, n_estimators=200, reg_alpha=1, reg_lambda=3, subsample=1.0; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=10, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=  13.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=10, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=  13.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=10, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=  13.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=10, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=  14.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=9, min_child_weight=10, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=  13.8s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=1, subsample=1.0; total time=  18.5s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=1, subsample=1.0; total time=  18.7s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=1, subsample=1.0; total time=  18.7s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=1, subsample=1.0; total time=  18.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=1, n_estimators=600, reg_alpha=3, reg_lambda=1, subsample=1.0; total time=  18.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=10, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=10, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=10, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=10, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=10, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=5, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=5, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=5, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=5, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, reg_alpha=0, reg_lambda=5, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  13.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  12.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  13.3s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=10, n_estimators=400, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=10, n_estimators=400, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=10, n_estimators=400, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=10, n_estimators=400, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  14.3s\n",
      "[CV] END colsample_bytree=0.3, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=10, n_estimators=400, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=0.8; total time=  28.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=0.8; total time=  25.3s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=0.8; total time=  26.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=0.8; total time=  25.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=9, min_child_weight=1, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=0.8; total time=  26.0s\n",
      "\n",
      "✅ Best XGBoost Parameters: {'subsample': 0.7, 'reg_lambda': 5, 'reg_alpha': 1, 'n_estimators': 600, 'min_child_weight': 10, 'max_depth': 5, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 0.7}\n",
      "\n",
      "✅ XGB Train Accuracy: 0.8379245787643755\n",
      "✅ XGB Test Accuracy: 0.777724949482943\n",
      "\n",
      "📄 Classification Report (Train):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      3894\n",
      "           1       0.86      0.95      0.90     20407\n",
      "           2       0.65      0.42      0.51      5115\n",
      "           3       0.85      0.81      0.83      4235\n",
      "\n",
      "    accuracy                           0.84     33651\n",
      "   macro avg       0.81      0.76      0.78     33651\n",
      "weighted avg       0.83      0.84      0.83     33651\n",
      "\n",
      "📄 Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.80      1014\n",
      "           1       0.82      0.92      0.87      5045\n",
      "           2       0.46      0.29      0.35      1325\n",
      "           3       0.74      0.74      0.74      1029\n",
      "\n",
      "    accuracy                           0.78      8413\n",
      "   macro avg       0.71      0.68      0.69      8413\n",
      "weighted avg       0.76      0.78      0.76      8413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=4,\n",
    "    tree_method='hist',\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "param_dist_xgb = {\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [200, 400, 600],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7],\n",
    "    'reg_lambda': [1, 3, 5],\n",
    "    'reg_alpha': [0, 1, 3],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist_xgb,\n",
    "    n_iter=40,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    # n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit\n",
    "xgb_search.fit(x_train_xgb, y_train_xgb)\n",
    "\n",
    "print(\"\\n✅ Best XGBoost Parameters:\", xgb_search.best_params_)\n",
    "\n",
    "# Predict\n",
    "xgb_pred_train = xgb_search.predict(x_train_xgb)\n",
    "xgb_pred_test = xgb_search.predict(x_test_xgb)\n",
    "\n",
    "print(\"\\n✅ XGB Train Accuracy:\", accuracy_score(y_train_xgb, xgb_pred_train))\n",
    "print(\"✅ XGB Test Accuracy:\", accuracy_score(y_test_xgb, xgb_pred_test))\n",
    "\n",
    "print(\"\\n📄 Classification Report (Train):\\n\", classification_report(y_train_xgb, xgb_pred_train))\n",
    "print(\"📄 Classification Report (Test):\\n\", classification_report(y_test_xgb, xgb_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34b82c-4d47-4268-aaf7-8f3e071cc242",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_final = lightgbm.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=4,\n",
    "    device='gpu',\n",
    "    boosting_type='goss',\n",
    "    class_weight='balanced',\n",
    "    num_leaves=31,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.015,\n",
    "    n_estimators=500,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.6,\n",
    "    feature_fraction=0.6,\n",
    "    reg_lambda=3,\n",
    "    reg_alpha=1,\n",
    "    min_child_samples=30,\n",
    "    min_split_gain=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e02eb20-f198-49e6-90ec-f766625276e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 3021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33651, number of used features: 53\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 6GB Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.51 MB) transferred to GPU in 0.005068 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002485 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003350 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002694 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002866 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002940 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002865 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002767 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002296 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003040 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002888 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002871 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003006 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003221 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002877 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003673 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003428 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003054 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002984 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002478 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002848 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002969 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003290 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003286 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002668 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003308 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003380 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003161 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002884 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003057 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002787 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002854 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003577 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002979 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003148 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002696 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002833 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003130 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003059 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002910 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002600 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003080 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002784 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003981 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003240 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002755 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002632 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004096 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003185 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002638 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002881 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003142 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003735 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003820 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003141 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003350 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003035 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003227 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003414 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003110 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003484 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003793 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003080 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002834 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002737 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003417 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002791 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002694 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003184 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003102 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003389 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003563 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003992 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003617 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002739 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003679 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002863 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002747 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003728 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003147 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002656 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002434 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003658 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003283 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003640 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004375 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004456 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002796 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.005004 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003729 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003537 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003770 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003242 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002959 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003039 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003046 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004081 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003166 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004866 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003788 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.005643 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004223 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002473 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004042 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004041 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004084 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004720 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004720 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003386 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003931 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003862 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003658 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004539 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003727 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003007 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003649 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002900 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003797 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004117 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003592 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002991 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003212 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002646 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002955 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004056 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004171 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002706 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004030 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003758 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003652 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003497 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003652 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004009 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003317 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003080 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002840 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003196 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002756 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003497 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002456 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003042 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002768 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003073 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002634 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003190 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003917 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004097 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002664 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002659 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003489 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003889 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003733 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003569 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002353 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003377 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003247 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002717 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002637 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.006174 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003341 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004543 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003235 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003558 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003393 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003539 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003895 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003388 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002851 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003468 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003417 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003320 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003902 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002924 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004020 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003119 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003421 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003052 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003294 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002536 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004287 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004924 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004299 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003189 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003491 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004265 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003126 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003376 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003028 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002915 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003255 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002598 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003941 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002958 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003383 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002486 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003093 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004093 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003773 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004040 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004451 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003334 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003014 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004269 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002914 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003623 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003304 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003722 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003314 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002821 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003001 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003958 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002948 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002485 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003273 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003035 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003088 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003999 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003053 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003840 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003178 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002930 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004353 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004538 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002921 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003056 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003720 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003826 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002715 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003083 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.005264 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003324 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003330 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003974 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003267 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003409 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003677 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003368 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003770 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003094 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003437 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004339 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002841 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002727 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004220 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003658 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003509 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004139 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003047 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003623 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003014 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003400 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002417 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004114 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.005568 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003909 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004422 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004206 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003027 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.005832 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004267 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002998 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003681 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004601 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003461 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004386 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003903 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003274 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003659 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004866 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003707 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004830 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003165 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004868 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.006120 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003676 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003149 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004885 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003872 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003468 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003369 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004064 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003041 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.005041 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003876 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002748 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003735 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003895 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002938 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.005030 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003588 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002589 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004600 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004029 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002613 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003969 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002680 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003899 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004899 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004901 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004028 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003987 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003344 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004577 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004633 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003052 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003862 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004032 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004396 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003527 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003558 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004618 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003990 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004331 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004977 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003145 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004811 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004065 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004893 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003409 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003356 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003266 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002729 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003613 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004984 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.005346 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003742 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003279 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003250 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003185 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002869 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004193 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003259 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003846 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003203 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002921 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004850 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002894 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004238 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.006149 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002511 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004520 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003312 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002945 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004625 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003626 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004586 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003607 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003269 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003691 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003502 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003958 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003878 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003973 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004107 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004777 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004833 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002567 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004403 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003971 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003180 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003973 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002880 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003341 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003691 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002937 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003352 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004589 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002889 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002682 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003379 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002929 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004362 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003911 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.005200 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003296 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002896 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003978 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003262 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003114 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003621 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004583 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003173 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002493 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003627 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002640 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003679 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003636 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003721 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002732 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003036 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003334 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003373 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.005283 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002943 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003994 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004776 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004429 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003119 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002792 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003045 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003796 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002719 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004915 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003370 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003016 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003622 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003394 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003012 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003492 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002991 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003661 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003146 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003037 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002700 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002861 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003463 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003043 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004024 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004649 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003632 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004082 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.005817 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003851 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003261 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003078 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004667 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002823 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.004115 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.003501 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.15 MB) transferred to GPU in 0.002667 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n"
     ]
    }
   ],
   "source": [
    "lgbm_final.fit(x_train, y_train)\n",
    "pred_test = lgbm_final.predict(x_test)\n",
    "pred_train = lgbm_final.predict(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "08373fbb-182a-4328-a97c-408c9394fed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7646726694600458\n",
      "Test accuracy:  0.7210269820515869\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \",accuracy_score(pred_train,y_train))\n",
    "print(\"Test accuracy: \",accuracy_score(pred_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b14851ff-6105-46f4-860c-4689517eb37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lightgbm.LGBMClassifier(\n",
    "    device='gpu',\n",
    "\n",
    "    # --- Tree Shape ---\n",
    "    num_leaves=90,          # more learned patterns\n",
    "    max_depth=12,           # deeper than default but not too deep\n",
    "\n",
    "    # --- Learning Control ---\n",
    "    learning_rate=0.03,     # faster than 0.01 but still stable\n",
    "    n_estimators=1200,       # more trees = smoother decision boundaries\n",
    "\n",
    "    # --- Regularization ---\n",
    "    reg_alpha=1,            # light L1\n",
    "    reg_lambda=3,           # moderate L2\n",
    "\n",
    "    # --- Feature/Subsample ---\n",
    "    feature_fraction=0.8,   # robust for noisy datasets\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=5,\n",
    "\n",
    "    # --- Class-specific improvement ---\n",
    "    min_data_in_leaf=60,    # reduces noise and improves P3 class\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "108ab0a4-ad72-472b-8f95-3ad7a22289ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 3015\n",
      "[LightGBM] [Info] Number of data points in the train set: 33651, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 6GB Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.51 MB) transferred to GPU in 0.002838 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -2.156606\n",
      "[LightGBM] [Info] Start training from score -0.500165\n",
      "[LightGBM] [Info] Start training from score -1.883865\n",
      "[LightGBM] [Info] Start training from score -2.072659\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003328 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.002712 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003625 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004234 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.002857 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.002783 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.002995 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003123 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003036 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003254 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004609 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003812 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004039 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003902 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004414 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003897 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004907 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004519 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004351 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004216 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003981 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003879 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005114 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004294 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004308 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004634 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004662 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004058 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004493 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004644 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004530 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004744 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005078 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005089 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004091 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004107 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004924 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003533 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005108 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003507 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005126 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003866 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.007448 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003762 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003394 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003394 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003492 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004414 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003577 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003739 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004624 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004051 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004256 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003401 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004434 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004313 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004860 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005083 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004499 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005189 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004969 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004496 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004298 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004880 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004588 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004852 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004538 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004254 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005151 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004678 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004417 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004762 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004217 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003255 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003943 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003242 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003863 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005084 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005974 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004768 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003577 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004848 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004642 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004559 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004901 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004427 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004382 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004533 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004908 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004827 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004325 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005285 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004971 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004565 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004886 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005971 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004878 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005167 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004803 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003878 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004721 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005195 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005419 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004784 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004673 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.006219 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004699 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005522 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005319 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003786 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004466 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005246 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003838 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004328 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004901 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004895 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004697 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004935 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004754 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004822 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004335 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003748 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004591 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005685 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004880 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005047 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004725 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004574 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004161 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003612 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004818 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004917 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004220 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004178 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004236 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005344 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004067 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004112 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004625 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004908 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004568 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004853 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004600 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004947 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004988 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004371 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004652 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004510 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004978 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.005230 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004857 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004909 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004836 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003771 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004851 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004294 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004676 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004892 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004936 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004035 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003830 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003926 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003563 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003908 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004063 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003582 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003837 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004266 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003856 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004069 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004113 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003784 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003901 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003707 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003952 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004094 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004057 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003643 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003838 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003826 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003787 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003853 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004099 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003924 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003621 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003295 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003517 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004258 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004197 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003408 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003649 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003611 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003721 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003424 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003850 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004092 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004087 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003591 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003660 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003514 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003176 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003479 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003489 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003674 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003708 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003871 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003902 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003789 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003841 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003887 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003968 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003560 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003965 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003876 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003655 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004103 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004244 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003266 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004036 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003428 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003866 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003859 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003470 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003710 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003394 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003524 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003469 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003973 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003745 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004381 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004179 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.004024 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003783 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003672 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (0.41 MB) transferred to GPU in 0.003930 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Test accuracy : 0.7694044930464757\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Train accuracy : 0.992957118659178\n"
     ]
    }
   ],
   "source": [
    "lgbm.fit(x_train, y_train)\n",
    "print('Test accuracy :',accuracy_score(lgbm.predict(x_test),y_test))\n",
    "print('Train accuracy :',accuracy_score(lgbm.predict(x_train),y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5571f51-7756-43c2-a565-5bf09bae9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "89692beb-26c4-4e20-bbbb-428204067f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8083266470535794\n",
      "Test accuracy:  0.7828360870082016\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    task_type=\"GPU\",\n",
    "    devices='0',\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Train accuracy: \",accuracy_score(model.predict(x_train),y_train))\n",
    "print(\"Test accuracy: \",accuracy_score(model.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3e21b088-a102-45a4-bcee-f3885cd360d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catboost base model gives almost same result after tunning xgboost and lightbgm means there could be a chance that \n",
    "# after tuning catboost out performe xgboost and lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fed07a2c-cdcf-4278-9bcd-4fdc529f9c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_cat = {\n",
    "    'depth': [6, 8, 10],\n",
    "    'learning_rate': [0.03, 0.06, 0.1],\n",
    "    'iterations': [500, 800, 1000],\n",
    "    'l2_leaf_reg': [1, 3, 5],\n",
    "    'bagging_temperature': [0, 0.5, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6b4df3a8-315f-4bf4-b221-9ec9335b275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cv = GridSearchCV(estimator=model,param_grid=param_grid_cat,cv=2,scoring='accuracy',verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "85532257-ce06-4b0b-81f7-e6c9a2c0bf3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 243 candidates, totalling 486 fits\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=   7.6s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=   7.5s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=   6.7s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=   6.6s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=   7.1s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=   6.5s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=   6.5s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=   7.1s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=   6.9s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=   6.6s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=   6.5s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=   7.6s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=   6.5s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=   6.8s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=   6.2s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=   6.7s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=   7.0s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=   6.6s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  12.1s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  11.8s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  12.0s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  10.6s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  10.9s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  11.2s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  10.4s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  10.4s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  11.4s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  11.4s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  10.9s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  11.2s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  10.8s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  10.8s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  11.3s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  11.5s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  10.7s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  11.4s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  13.2s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  12.9s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  13.1s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  12.9s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  13.8s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  13.0s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  14.4s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  13.1s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  13.5s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  13.8s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  14.2s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  12.0s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  13.3s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  13.6s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  12.6s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  11.6s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  12.0s\n",
      "[CV] END bagging_temperature=0, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  12.1s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=   9.6s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=   9.7s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=   9.8s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=  10.4s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=  10.0s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=  10.6s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=  10.1s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=   9.2s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=   9.4s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=   9.9s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=   9.7s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=   9.4s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=   9.3s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=  10.5s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=   9.8s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=  10.3s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=  10.5s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=  10.0s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  16.7s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  16.2s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  16.8s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  16.2s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  16.4s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  16.2s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  15.6s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  15.6s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  15.7s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  16.1s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  16.2s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  16.6s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  15.7s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  15.7s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  16.2s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  15.7s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  15.9s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  16.1s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  20.1s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  21.4s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  23.2s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  23.9s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  22.4s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  22.1s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  21.1s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  21.6s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  21.5s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  21.6s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  22.0s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  22.2s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  20.2s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  20.6s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  21.5s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  21.0s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  21.2s\n",
      "[CV] END bagging_temperature=0, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  21.9s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=  20.0s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=  20.9s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=  21.2s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=  22.2s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=  21.6s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=  21.2s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=  20.1s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=  20.5s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=  21.9s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=  23.0s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=  22.2s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=  21.7s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=  21.0s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=  21.6s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=  20.9s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=  21.4s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=  22.3s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=  21.7s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  35.8s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  34.0s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  34.7s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  35.8s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  36.3s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  34.1s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  32.7s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  34.6s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  36.3s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  35.3s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  33.6s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  34.5s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  32.2s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  34.6s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  33.3s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  32.3s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  32.3s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  32.5s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  42.2s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  43.5s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  41.8s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  42.1s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  41.4s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  42.1s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  41.1s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  41.6s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  41.9s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  41.2s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  40.9s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  43.6s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  41.3s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  40.0s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  41.8s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  41.3s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  40.6s\n",
      "[CV] END bagging_temperature=0, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  42.0s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=   6.8s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=   6.6s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=   6.9s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=   6.5s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=   6.8s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=   7.0s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=   6.4s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=   6.7s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=   6.7s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=   8.4s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=   7.5s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=   6.5s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=   6.2s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=   7.1s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=   7.3s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=   6.5s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=   7.2s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=   6.7s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  10.3s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  10.4s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  10.5s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  10.2s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  10.4s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  10.4s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  10.1s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  10.5s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  10.8s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  10.2s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  11.2s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  11.4s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  10.4s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  10.2s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  10.4s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  10.2s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  10.5s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  11.2s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  12.9s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  13.0s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  14.3s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  15.0s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  13.9s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  12.7s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  12.1s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  13.0s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  13.1s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  13.0s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  13.0s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  14.5s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  13.3s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  12.8s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  12.9s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  12.8s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  12.5s\n",
      "[CV] END bagging_temperature=0.5, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  12.9s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=  10.4s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=  10.5s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=  11.4s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=  10.5s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=  12.0s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=  10.2s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=  10.2s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=  10.4s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=  10.0s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=  10.3s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=  10.3s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=  10.7s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=  10.0s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=  10.6s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=  10.0s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=  12.0s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=  10.8s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=  10.2s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  16.7s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  16.4s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  16.4s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  17.4s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  17.1s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  17.3s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  16.3s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  15.9s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  16.2s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  16.4s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  16.5s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  16.8s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  17.9s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  15.3s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  15.4s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  15.4s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  15.7s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  16.1s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  25.1s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  23.3s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  22.0s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  22.3s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  22.6s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  23.5s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  23.1s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  21.5s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  21.7s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  21.7s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  22.6s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  24.1s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  22.2s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  20.3s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  21.0s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  22.5s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  22.0s\n",
      "[CV] END bagging_temperature=0.5, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  20.5s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=  20.7s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=  21.2s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=  20.8s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=  22.2s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=  21.3s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=  21.6s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=  20.2s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=  20.8s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=  20.7s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=  21.0s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=  21.3s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=  21.6s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=  20.0s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=  20.7s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=  20.4s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=  21.1s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=  21.9s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=  20.8s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  33.6s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  34.8s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  35.7s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  35.2s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  34.9s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  36.6s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  32.8s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  32.6s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  34.8s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  35.5s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  34.8s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  37.1s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  33.9s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  32.6s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  32.3s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  32.9s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  33.8s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  32.7s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  41.6s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  43.3s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  42.3s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  43.1s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  43.7s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  43.1s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  41.9s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  41.2s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  41.3s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  45.8s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  43.8s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  42.7s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  42.2s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  41.2s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  42.1s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  43.2s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  43.2s\n",
      "[CV] END bagging_temperature=0.5, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  43.6s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=   8.5s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=   8.1s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=   8.4s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=   9.1s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=   7.5s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=   7.6s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=   7.7s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=   8.6s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=   8.2s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=   7.6s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=   7.5s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=   8.5s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=   7.6s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=   8.0s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=   9.5s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=   7.5s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=   7.5s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=   7.3s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  11.0s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  10.5s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  10.9s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  11.3s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  11.2s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  11.5s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  10.9s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  11.2s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  11.0s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  11.4s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  11.6s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  10.7s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  10.5s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  11.0s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  10.7s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  11.2s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  11.5s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  11.0s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  14.3s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  14.8s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  12.9s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  14.2s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  13.2s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  13.3s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  14.2s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  13.3s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  15.0s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  15.6s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  15.8s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  12.8s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  12.9s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  13.2s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  12.9s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  12.8s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  13.8s\n",
      "[CV] END bagging_temperature=1, depth=6, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  13.2s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=  10.9s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=  12.4s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=  12.5s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=  10.8s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=  11.4s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=  10.5s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=  10.1s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=  11.0s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=  11.9s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=  11.8s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=  10.8s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=  11.7s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=  10.9s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=  11.3s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=  10.3s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=  10.4s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=  10.6s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=  10.8s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  17.3s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  17.3s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  17.1s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  17.8s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  17.4s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  17.8s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  16.9s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  17.3s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  16.6s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  17.3s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  16.9s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  16.0s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  16.6s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  16.0s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  16.3s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  16.3s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  18.1s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  21.0s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  21.6s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  22.9s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  21.0s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  21.1s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  20.9s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  20.5s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  18.8s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  20.1s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  21.4s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  20.6s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  21.6s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  20.9s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  19.4s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  20.0s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  20.2s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  19.9s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  20.8s\n",
      "[CV] END bagging_temperature=1, depth=8, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  20.0s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=  20.0s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.03; total time=  20.7s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=  21.5s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.06; total time=  22.5s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=  22.5s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=1, learning_rate=0.1; total time=  22.1s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=  20.2s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.03; total time=  21.2s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=  20.6s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.06; total time=  21.8s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=  21.6s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.1; total time=  21.3s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=  21.2s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.03; total time=  21.0s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=  20.7s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.06; total time=  22.3s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=  20.8s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=500, l2_leaf_reg=5, learning_rate=0.1; total time=  21.0s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  34.9s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.03; total time=  35.3s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  36.4s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.06; total time=  35.8s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  35.7s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=1, learning_rate=0.1; total time=  36.4s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  32.6s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.03; total time=  33.6s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  34.0s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.06; total time=  34.0s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  33.1s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=3, learning_rate=0.1; total time=  33.8s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  32.5s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.03; total time=  31.5s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  32.2s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.06; total time=  32.3s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  33.3s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=800, l2_leaf_reg=5, learning_rate=0.1; total time=  31.4s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  41.3s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.03; total time=  42.3s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  43.7s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.06; total time=  43.5s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  42.2s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=1, learning_rate=0.1; total time=  42.6s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  40.8s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.03; total time=  41.5s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  39.3s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.06; total time=  40.7s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  40.6s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=3, learning_rate=0.1; total time=  42.0s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  39.5s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.03; total time=  40.2s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  42.0s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.06; total time=  41.8s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  41.7s\n",
      "[CV] END bagging_temperature=1, depth=10, iterations=1000, l2_leaf_reg=5, learning_rate=0.1; total time=  41.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=&lt;catboost.core.CatBoostClassifier object at 0x00000183B51B9BE0&gt;,\n",
       "             param_grid={&#x27;bagging_temperature&#x27;: [0, 0.5, 1],\n",
       "                         &#x27;depth&#x27;: [6, 8, 10], &#x27;iterations&#x27;: [500, 800, 1000],\n",
       "                         &#x27;l2_leaf_reg&#x27;: [1, 3, 5],\n",
       "                         &#x27;learning_rate&#x27;: [0.03, 0.06, 0.1]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">&lt;catboost.cor...00183B51B9BE0&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">param_grid&nbsp;</td>\n",
       "            <td class=\"value\">{&#x27;bagging_temperature&#x27;: [0, 0.5, ...], &#x27;depth&#x27;: [6, 8, ...], &#x27;iterations&#x27;: [500, 800, ...], &#x27;l2_leaf_reg&#x27;: [1, 3, ...], ...}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scoring&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;accuracy&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">refit&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cv&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">pre_dispatch&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">error_score&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">return_train_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: CatBoostClassifier</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x00000183E22BC0E0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CatBoostClassifier</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x00000183E22BC0E0&gt;</pre></div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=<catboost.core.CatBoostClassifier object at 0x00000183B51B9BE0>,\n",
       "             param_grid={'bagging_temperature': [0, 0.5, 1],\n",
       "                         'depth': [6, 8, 10], 'iterations': [500, 800, 1000],\n",
       "                         'l2_leaf_reg': [1, 3, 5],\n",
       "                         'learning_rate': [0.03, 0.06, 0.1]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "efc13256-cb02-4623-a872-3abdf68baa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter:  {'bagging_temperature': 1, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.03}\n",
      "Best accuracy:  0.7835726390329549\n"
     ]
    }
   ],
   "source": [
    "print('Best parameter: ',cat_cv.best_params_)\n",
    "print('Best accuracy: ',cat_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e387b276-eb2c-41e1-9719-99033eb0e5d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[32m      3\u001b[39m model = CatBoostClassifier(\n\u001b[32m      4\u001b[39m     task_type=\u001b[33m\"\u001b[39m\u001b[33mGPU\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     devices=\u001b[33m'\u001b[39m\u001b[33m0\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     verbose=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     12\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m model.fit(\u001b[43mx_train\u001b[49m, y_train)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrain accuracy: \u001b[39m\u001b[33m\"\u001b[39m,accuracy_score(model.predict(x_train),y_train))\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTest accuracy: \u001b[39m\u001b[33m\"\u001b[39m,accuracy_score(model.predict(x_test),y_test))\n",
      "\u001b[31mNameError\u001b[39m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    task_type=\"GPU\",\n",
    "    devices='0',\n",
    "    bagging_temperature= 1,\n",
    "    depth = 6,\n",
    "    iterations =  500,\n",
    "    l2_leaf_reg = 1,\n",
    "    learning_rate = 0.03,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Train accuracy: \",accuracy_score(model.predict(x_train),y_train))\n",
    "print(\"Test accuracy: \",accuracy_score(model.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158b4d15-04f8-4d0b-81a1-a008fd7513e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy: \",accuracy_score(model.predict(x_train),y_train))\n",
    "print(\"Test accuracy: \",accuracy_score(model.predict(x_test),y_test))\n",
    "print(\"Classification report on train data\\n\",classification_report(model.predict(x_train),y_train))\n",
    "print(\"Classification report on test data\\n\",classification_report(model.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e497785-b8c3-49e8-ad29-00e2045d6b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e803be96-1f4a-4335-93c4-c533472c329e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4eda0ab5-2d89-49ce-a7b1-19fdb6775f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d26588f-54a7-4dd7-8509-3a3b3bb853f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f25aae50-e77b-498e-a54f-8aff978e6860",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6742e6a1-a61e-4438-aa0a-80a3f0cdcdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost is generalizing well compared to xgboost and lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1546eb76-bb9c-4c52-99fb-9553a1240ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "importance = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "885ccedb-5052-4f6a-9a78-bab02ded345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pct_tl_open_L6M : 0.46455810151430327\n",
      "pct_tl_closed_L6M : 0.0971001397770839\n",
      "Tot_TL_closed_L12M : 0.03592210081603227\n",
      "pct_tl_closed_L12M : 0.20797878432127428\n",
      "Tot_Missed_Pmnt : 0.12075839244464176\n",
      "CC_TL : 0.004905686259036478\n",
      "Home_TL : 0.020085310386162975\n",
      "PL_TL : 0.009787532552186274\n",
      "Secured_TL : 0.45625392356566247\n",
      "Unsecured_TL : 0.3463941944977098\n",
      "Other_TL : 0.19289524660888704\n",
      "Age_Oldest_TL : 22.572514639531637\n",
      "Age_Newest_TL : 3.007029201071869\n",
      "time_since_recent_payment : 1.5469183277651484\n",
      "max_recent_level_of_deliq : 13.436081665494578\n",
      "num_deliq_6_12mts : 2.648962625869032\n",
      "num_times_60p_dpd : 1.3632122803656501\n",
      "num_std_12mts : 10.927843697372564\n",
      "num_sub : 0.010680090322304653\n",
      "num_sub_6mts : 0.0012928003157873771\n",
      "num_sub_12mts : 0.00010662278972410094\n",
      "num_dbt : 0.001867180548849496\n",
      "num_dbt_12mts : 0.0005480419400564255\n",
      "num_lss : 0.002265510963605263\n",
      "recent_level_of_deliq : 4.543098814312452\n",
      "CC_enq_L12m : 0.04141881530157753\n",
      "PL_enq_L12m : 0.2950682513576474\n",
      "time_since_recent_enq : 9.524672126269872\n",
      "enq_L3m : 20.492294170733558\n",
      "NETMONTHLYINCOME : 0.29417227943531343\n",
      "Time_With_Curr_Empr : 0.4112577598513219\n",
      "CC_Flag : 0.04535214903474871\n",
      "PL_Flag : 0.0\n",
      "pct_PL_enq_L6m_of_ever : 6.044011683046253\n",
      "pct_CC_enq_L6m_of_ever : 0.03709461994385595\n",
      "HL_Flag : 0.08256466940620107\n",
      "GL_Flag : 0.07958682748660428\n",
      "EDUCATION : 0.04874853817436509\n",
      "MARITALSTATUS_Married : 0.03435280876073728\n",
      "MARITALSTATUS_Single : 0.0\n",
      "GENDER_F : 0.05921006242783678\n",
      "GENDER_M : 0.0\n",
      "last_prod_enq2_AL : 0.0121435709242981\n",
      "last_prod_enq2_CC : 0.0\n",
      "last_prod_enq2_ConsumerLoan : 0.017420164043313167\n",
      "last_prod_enq2_HL : 0.00757244529966983\n",
      "last_prod_enq2_PL : 0.052727162200297\n",
      "last_prod_enq2_others : 0.02303395688776423\n",
      "first_prod_enq2_AL : 0.08629715386380267\n",
      "first_prod_enq2_CC : 0.010615346993873863\n",
      "first_prod_enq2_ConsumerLoan : 0.010356643995511963\n",
      "first_prod_enq2_HL : 0.0\n",
      "first_prod_enq2_PL : 0.16514421997111225\n",
      "first_prod_enq2_others : 0.10582366318419248\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_ = model  # your trained model\n",
    "feature_importances = model_.get_feature_importance()\n",
    "\n",
    "for name, score in zip(x_train.columns, feature_importances):\n",
    "    print(f\"{name} : {score}\")\n",
    "    features.append({\"feature\":name})\n",
    "    importance.append({\"importance\":score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1c612b83-249a-4be4-ba7a-333c540a2621",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.concat([pd.DataFrame(features),pd.DataFrame(importance)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "634e1968-f06b-40da-bf2d-875e6b87bd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Age_Oldest_TL</td>\n",
       "      <td>22.572515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>enq_L3m</td>\n",
       "      <td>20.492294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max_recent_level_of_deliq</td>\n",
       "      <td>13.436082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num_std_12mts</td>\n",
       "      <td>10.927844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>time_since_recent_enq</td>\n",
       "      <td>9.524672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature  importance\n",
       "11              Age_Oldest_TL   22.572515\n",
       "28                    enq_L3m   20.492294\n",
       "14  max_recent_level_of_deliq   13.436082\n",
       "17              num_std_12mts   10.927844\n",
       "27      time_since_recent_enq    9.524672"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_five_feature = feature_imp.sort_values(by='importance',ascending=False).head()\n",
    "top_five_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "073c79d5-ddf3-4c8b-bb70-ff995437d736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>GENDER_M</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>last_prod_enq2_CC</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MARITALSTATUS_Single</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>first_prod_enq2_HL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PL_Flag</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature  importance\n",
       "41              GENDER_M         0.0\n",
       "43     last_prod_enq2_CC         0.0\n",
       "39  MARITALSTATUS_Single         0.0\n",
       "51    first_prod_enq2_HL         0.0\n",
       "32               PL_Flag         0.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_imp_five_feature = feature_imp.sort_values(by='importance',ascending=True).head()\n",
    "less_imp_five_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e6aa6ae8-b55b-4c89-b7c7-ffd7d4e4308f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.barh(x_train.columns, feature_importances)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "59582e82-deb2-4a36-ac94-e33aa5d8bac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1150x660 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(x_test)\n",
    "shap.summary_plot(shap_values, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e4ebffc-95e0-48f0-a722-2ccb5893d7e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Use pickle to dump the trained model object into a file\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(cat_boost, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     pickle.dump(\u001b[43mmodel\u001b[49m, file)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel successfully saved as \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat_boost\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Define the filename for the model\n",
    "cat_boost = 'model.pkl'\n",
    "\n",
    "# Use pickle to dump the trained model object into a file\n",
    "with open(cat_boost, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(f\"Model successfully saved as '{cat_boost}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6cd498-1bd5-4f36-90ea-a38c3cb8e8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Credit Lending Env",
   "language": "python",
   "name": "credit_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
